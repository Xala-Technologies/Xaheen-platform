# OpenTelemetry Collector Configuration for {{projectName}}
# Generated by Xaheen CLI - Story 4.3 Monitoring and Observability
# Environment: {{environment}}

# Receivers collect telemetry data from various sources
receivers:
  # OTLP receiver for traces, metrics, and logs
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
        max_recv_msg_size_mib: 32
        max_concurrent_streams: 16
        read_buffer_size: 512
        write_buffer_size: 512
      http:
        endpoint: 0.0.0.0:4318
        max_request_body_size_mib: 32
        include_metadata: true
        cors:
          allowed_origins:
            - "http://localhost:*"
            - "https://localhost:*"
            {{#if environment}}
            {{#eq environment 'production'}}
            - "https://*.{{projectName}}.com"
            {{/eq}}
            {{/if}}

  # Prometheus receiver for scraping metrics
  prometheus:
    config:
      global:
        scrape_interval: 30s
        evaluation_interval: 30s
      scrape_configs:
        - job_name: 'otel-collector'
          scrape_interval: 10s
          static_configs:
            - targets: ['0.0.0.0:8888']
        
        {{#if features.includes('prometheus')}}
        # Scrape from existing Prometheus targets
        - job_name: '{{projectName}}'
          scrape_interval: 15s
          static_configs:
            - targets: 
              {{#each prometheus.serviceDiscovery.staticConfigs}}
              {{#each targets}}
              - '{{this}}'
              {{/each}}
              {{/each}}
          metrics_path: /metrics
        {{/if}}

  # Jaeger receiver (legacy support)
  {{#if features.includes('jaeger')}}
  jaeger:
    protocols:
      grpc:
        endpoint: 0.0.0.0:14250
      thrift_http:
        endpoint: 0.0.0.0:14268
      thrift_compact:
        endpoint: 0.0.0.0:6831
      thrift_binary:
        endpoint: 0.0.0.0:6832
  {{/if}}

  # Zipkin receiver
  zipkin:
    endpoint: 0.0.0.0:9411

  # Host metrics receiver for infrastructure monitoring
  hostmetrics:
    collection_interval: 30s
    scrapers:
      cpu:
        metrics:
          system.cpu.utilization:
            enabled: true
      disk:
        metrics:
          system.disk.operations:
            enabled: true
          system.disk.io:
            enabled: true
          system.disk.io_time:
            enabled: true
      filesystem:
        metrics:
          system.filesystem.utilization:
            enabled: true
      load:
        metrics:
          system.linux.load_average_1m:
            enabled: true
          system.linux.load_average_5m:
            enabled: true
          system.linux.load_average_15m:
            enabled: true
      memory:
        metrics:
          system.memory.utilization:
            enabled: true
      network:
        metrics:
          system.network.connections:
            enabled: true
          system.network.packets:
            enabled: true
          system.network.errors:
            enabled: true
      processes:
        metrics:
          system.processes.count:
            enabled: true
          system.processes.created:
            enabled: true
      process:
        metrics:
          process.cpu.utilization:
            enabled: true
          process.memory.utilization:
            enabled: true
        mute_process_name_error: true

  {{#if kubernetes}}
  # Kubernetes receiver for cluster metrics
  k8s_cluster:
    collection_interval: 30s
    node_conditions_to_report: [Ready, MemoryPressure, DiskPressure, PIDPressure]
    allocatable_types_to_report: [cpu, memory, ephemeral-storage, storage]

  # Kubernetes events receiver
  k8s_events:
    auth_type: serviceAccount
    namespaces: [{{kubernetes.namespace}}, kube-system, default]
  {{/if}}

# Processors modify, filter, or batch telemetry data
processors:
  # Memory limiter prevents OOM situations
  memory_limiter:
    check_interval: 1s
    limit_mib: 512
    spike_limit_mib: 128

  # Batch processor batches telemetry data to reduce API calls
  batch:
    send_batch_size: 8192
    send_batch_max_size: 16384
    timeout: 5s

  # Resource processor adds/modifies resource attributes
  resource:
    attributes:
      - key: service.name
        value: {{projectName}}
        action: upsert
      - key: service.version
        value: "1.0.0"
        action: upsert
      - key: deployment.environment
        value: {{environment}}
        action: upsert
      - key: service.namespace
        value: {{#if kubernetes}}{{kubernetes.namespace}}{{else}}default{{/if}}
        action: upsert
      {{#if kubernetes}}
      - key: k8s.cluster.name
        value: {{kubernetes.namespace}}-cluster
        action: upsert
      {{/if}}

  # Attributes processor for filtering and transformation
  attributes/common:
    actions:
      - key: http.user_agent
        action: delete
      - key: net.peer.ip
        action: hash
      - key: enduser.id
        action: hash

  # Resource detection processor
  resourcedetection:
    detectors: [env, system, docker]
    timeout: 5s
    override: false

  # Span processor for trace sampling and filtering
  {{#if features.includes('distributed-tracing')}}
  probabilistic_sampler:
    sampling_percentage: {{#if environment}}{{#eq environment 'production'}}10{{else}}100{{/eq}}{{else}}100{{/if}}
    hash_seed: 42

  # Tail sampling processor for more sophisticated sampling
  tail_sampling:
    decision_wait: 10s
    num_traces: 50000
    expected_new_traces_per_sec: 10
    policies:
      - name: errors
        type: status_code
        status_code: {status_codes: [ERROR]}
      - name: slow_requests
        type: latency
        latency: {threshold_ms: 1000}
      - name: random_sampling
        type: probabilistic
        probabilistic: {sampling_percentage: {{#if environment}}{{#eq environment 'production'}}1{{else}}10{{/eq}}{{else}}10{{/if}}}
  {{/if}}

  # Transform processor for advanced data transformation
  transform:
    metric_statements:
      - context: metric
        statements:
          - set(description, "Updated description") where name == "http_requests_total"
    trace_statements:
      - context: span
        statements:
          - set(attributes["custom.processed"], true)
          - delete_key(attributes, "http.request.header.authorization")

# Exporters send telemetry data to various backends
exporters:
  # Logging exporter for debugging
  logging:
    loglevel: {{#if environment}}{{#eq environment 'production'}}warn{{else}}debug{{/eq}}{{else}}debug{{/if}}
    sampling_initial: 5
    sampling_thereafter: 200

  {{#if features.includes('prometheus')}}
  # Prometheus exporter
  prometheus:
    endpoint: "0.0.0.0:8889"
    namespace: {{projectName}}
    const_labels:
      environment: {{environment}}
      service: {{projectName}}
    send_timestamps: true
    metric_expiration: 180m
    enable_open_metrics: true
    resource_to_telemetry_conversion:
      enabled: true
  {{/if}}

  {{#if features.includes('jaeger')}}
  # Jaeger exporter
  jaeger:
    endpoint: {{#if kubernetes}}jaeger.{{kubernetes.namespace}}.svc.cluster.local:14250{{else}}jaeger:14250{{/if}}
    tls:
      insecure: true
    sending_queue:
      queue_size: 5000
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 120s
  {{/if}}

  {{#if features.includes('tempo')}}
  # Tempo exporter (via OTLP)
  otlp/tempo:
    endpoint: {{#if kubernetes}}tempo.{{kubernetes.namespace}}.svc.cluster.local:4317{{else}}tempo:4317{{/if}}
    tls:
      insecure: true
    sending_queue:
      queue_size: 5000
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 120s
  {{/if}}

  {{#if features.includes('loki')}}
  # Loki exporter for logs
  loki:
    endpoint: {{#if kubernetes}}http://loki.{{kubernetes.namespace}}.svc.cluster.local:3100/loki/api/v1/push{{else}}http://loki:3100/loki/api/v1/push{{/if}}
    labels:
      attributes:
        service.name: "service_name"
        service.namespace: "service_namespace"
        deployment.environment: "environment"
      resource:
        container.name: "container_name"
        k8s.pod.name: "pod_name"
        k8s.namespace.name: "namespace"
    format: json
    {{#if features.includes('distributed-tracing')}}
    # Enable trace correlation in logs
    tenant_id: {{projectName}}
    {{/if}}
  {{/if}}

  # OTLP exporter for external systems
  otlp/external:
    endpoint: ${OTEL_EXPORTER_OTLP_ENDPOINT}
    headers:
      Authorization: "Bearer ${OTEL_EXPORTER_OTLP_TOKEN}"
    tls:
      insecure: false
      ca_file: /etc/ssl/certs/ca-certificates.crt
    sending_queue:
      queue_size: 5000
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 120s

  {{#if environment}}
  {{#eq environment 'production'}}
  # Cloud-specific exporters for production
  
  # AWS X-Ray exporter
  # awsxray:
  #   no_verify_ssl: false
  #   local_mode: false
  #   region: us-east-1
  #   resource_arn: "arn:aws:ecs:us-east-1:123456789012:cluster/{{projectName}}"

  # Google Cloud Trace exporter
  # googlecloud:
  #   project: "{{projectName}}-prod"
  #   user_agent: "opentelemetry-collector-contrib {{version}}"

  # Azure Monitor exporter
  # azuremonitor:
  #   instrumentation_key: "${AZURE_MONITOR_INSTRUMENTATION_KEY}"
  #   maxbatchsize: 100
  #   maxbatchinterval: 10s
  {{/eq}}
  {{/if}}

# Extensions provide additional functionality
extensions:
  # Health check extension
  health_check:
    endpoint: 0.0.0.0:13133
    path: "/health"
    check_collector_pipeline:
      enabled: true
      interval: 5s
      exporter_failure_threshold: 5

  # Performance profiling extension
  pprof:
    endpoint: 0.0.0.0:1777
    block_profile_fraction: 0
    mutex_profile_fraction: 0
    save_to_file: ""

  # zPages extension for debugging
  zpages:
    endpoint: 0.0.0.0:55679

  # File storage extension for persistent queues
  file_storage:
    directory: /tmp/otel-collector-storage
    timeout: 10s

  # Basic authenticator (if needed)
  basicauth/client:
    client_auth:
      username: ${BASIC_AUTH_USERNAME}
      password: ${BASIC_AUTH_PASSWORD}

# Service configuration defines the telemetry pipeline
service:
  extensions: [health_check, pprof, zpages, file_storage]
  
  pipelines:
    # Traces pipeline
    traces:
      receivers: [otlp{{#if features.includes('jaeger')}}, jaeger{{/if}}, zipkin]
      processors: 
        - memory_limiter
        - resourcedetection
        - resource
        - attributes/common
        {{#if features.includes('distributed-tracing')}}
        - probabilistic_sampler
        - tail_sampling
        {{/if}}
        - batch
      exporters: 
        - logging
        {{#if features.includes('jaeger')}}
        - jaeger
        {{/if}}
        {{#if features.includes('tempo')}}
        - otlp/tempo
        {{/if}}
        {{#if environment}}
        {{#neq environment 'development'}}
        - otlp/external
        {{/neq}}
        {{/if}}

    # Metrics pipeline
    metrics:
      receivers: [otlp, prometheus, hostmetrics{{#if kubernetes}}, k8s_cluster{{/if}}]
      processors:
        - memory_limiter
        - resourcedetection
        - resource
        - transform
        - batch
      exporters:
        - logging
        {{#if features.includes('prometheus')}}
        - prometheus
        {{/if}}
        {{#if environment}}
        {{#neq environment 'development'}}
        - otlp/external
        {{/neq}}
        {{/if}}

    # Logs pipeline
    logs:
      receivers: [otlp{{#if kubernetes}}, k8s_events{{/if}}]
      processors:
        - memory_limiter
        - resourcedetection
        - resource
        - attributes/common
        - batch
      exporters:
        - logging
        {{#if features.includes('loki')}}
        - loki
        {{/if}}
        {{#if environment}}
        {{#neq environment 'development'}}
        - otlp/external
        {{/neq}}
        {{/if}}

  # Telemetry configuration for the collector itself
  telemetry:
    logs:
      level: {{#if environment}}{{#eq environment 'production'}}warn{{else}}info{{/eq}}{{else}}info{{/if}}
      development: {{#if environment}}{{#eq environment 'development'}}true{{else}}false{{/eq}}{{else}}true{{/if}}
      encoding: json
      disable_caller: false
      disable_stacktrace: false
      sampling:
        enabled: true
        tick: 10s
        initial: 10
        thereafter: 100
    
    metrics:
      level: detailed
      address: 0.0.0.0:8888
      readers:
        - periodic:
            interval: 30s
            timeout: 5s

    traces:
      {{#if features.includes('distributed-tracing')}}
      processors:
        - batch:
            timeout: 1s
            send_batch_size: 1024
      {{/if}}

# Resource configuration
resource:
  attributes:
    - key: service.name
      value: "otel-collector-{{projectName}}"
    - key: service.version
      value: "{{opentelemetry.version}}"
    - key: deployment.environment
      value: "{{environment}}"
    {{#if kubernetes}}
    - key: k8s.cluster.name
      value: "{{kubernetes.namespace}}-cluster"
    - key: k8s.namespace.name
      value: "{{kubernetes.namespace}}"
    {{/if}}