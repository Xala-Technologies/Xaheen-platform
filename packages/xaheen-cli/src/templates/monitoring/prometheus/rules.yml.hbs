# Prometheus Recording Rules for {{projectName}}
# Generated by Xaheen CLI - Story 4.3 Monitoring and Observability
# Environment: {{environment}}

groups:
  - name: "{{projectName}}.instance.rules"
    interval: 30s
    rules:
      # Instance-level aggregations for better performance and storage efficiency
      
      # CPU Utilization Rules
      - record: instance:node_cpu_utilisation:rate5m
        expr: |
          1 - avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m]))
        labels:
          rule_type: "instance_level"

      - record: instance:node_cpu_utilisation:rate1m
        expr: |
          1 - avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[1m]))
        labels:
          rule_type: "instance_level"

      # Load Average Rules
      - record: instance:node_load1_per_cpu:ratio
        expr: |
          node_load1 / count by (instance) (node_cpu_seconds_total{mode="idle"})
        labels:
          rule_type: "instance_level"

      - record: instance:node_load5_per_cpu:ratio
        expr: |
          node_load5 / count by (instance) (node_cpu_seconds_total{mode="idle"})
        labels:
          rule_type: "instance_level"

      - record: instance:node_load15_per_cpu:ratio
        expr: |
          node_load15 / count by (instance) (node_cpu_seconds_total{mode="idle"})
        labels:
          rule_type: "instance_level"

      # Memory Utilization Rules
      - record: instance:node_memory_utilisation:ratio
        expr: |
          1 - (
            (
              node_memory_MemAvailable_bytes or 
              (
                node_memory_Buffers_bytes + 
                node_memory_Cached_bytes + 
                node_memory_MemFree_bytes
              )
            ) / node_memory_MemTotal_bytes
          )
        labels:
          rule_type: "instance_level"

      - record: instance:node_memory_available:bytes
        expr: |
          node_memory_MemAvailable_bytes or 
          (
            node_memory_Buffers_bytes + 
            node_memory_Cached_bytes + 
            node_memory_MemFree_bytes
          )
        labels:
          rule_type: "instance_level"

      # Disk I/O Rules
      - record: instance:node_disk_io_time_seconds:rate5m
        expr: |
          rate(node_disk_io_time_seconds_total[5m])
        labels:
          rule_type: "instance_level"

      - record: instance:node_disk_reads_completed:rate5m
        expr: |
          rate(node_disk_reads_completed_total[5m])
        labels:
          rule_type: "instance_level"

      - record: instance:node_disk_writes_completed:rate5m
        expr: |
          rate(node_disk_writes_completed_total[5m])
        labels:
          rule_type: "instance_level"

      # Network I/O Rules
      - record: instance:node_network_receive_bytes_excluding_lo:rate5m
        expr: |
          sum by (instance) (rate(node_network_receive_bytes_total{device!="lo"}[5m]))
        labels:
          rule_type: "instance_level"

      - record: instance:node_network_transmit_bytes_excluding_lo:rate5m
        expr: |
          sum by (instance) (rate(node_network_transmit_bytes_total{device!="lo"}[5m]))
        labels:
          rule_type: "instance_level"

      - record: instance:node_network_receive_drop_excluding_lo:rate5m
        expr: |
          sum by (instance) (rate(node_network_receive_drop_total{device!="lo"}[5m]))
        labels:
          rule_type: "instance_level"

      - record: instance:node_network_transmit_drop_excluding_lo:rate5m
        expr: |
          sum by (instance) (rate(node_network_transmit_drop_total{device!="lo"}[5m]))
        labels:
          rule_type: "instance_level"

      # Filesystem Rules
      - record: instance:node_filesystem_avail_percent
        expr: |
          (node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100
        labels:
          rule_type: "instance_level"

      - record: instance:node_filesystem_usage_percent
        expr: |
          ((node_filesystem_size_bytes - node_filesystem_avail_bytes) / node_filesystem_size_bytes) * 100
        labels:
          rule_type: "instance_level"

  - name: "{{projectName}}.application.rules"
    interval: 30s
    rules:
      # Application-level aggregations
      
      # HTTP Request Rules
      - record: job:http_requests:rate5m
        expr: |
          sum by (job) (rate(http_requests_total[5m]))
        labels:
          rule_type: "application_level"

      - record: job:http_requests:rate1m
        expr: |
          sum by (job) (rate(http_requests_total[1m]))
        labels:
          rule_type: "application_level"

      - record: job:http_requests_by_status:rate5m
        expr: |
          sum by (job, status) (rate(http_requests_total[5m]))
        labels:
          rule_type: "application_level"

      # Error Rate Rules
      - record: job:http_requests_error_rate:ratio5m
        expr: |
          sum by (job) (rate(http_requests_total{status=~"5.."}[5m])) /
          sum by (job) (rate(http_requests_total[5m]))
        labels:
          rule_type: "application_level"

      - record: job:http_requests_client_error_rate:ratio5m
        expr: |
          sum by (job) (rate(http_requests_total{status=~"4.."}[5m])) /
          sum by (job) (rate(http_requests_total[5m]))
        labels:
          rule_type: "application_level"

      # Latency Rules
      - record: job:http_request_duration:p50
        expr: |
          histogram_quantile(0.50, 
            sum by (job, le) (rate(http_request_duration_seconds_bucket[5m]))
          )
        labels:
          rule_type: "application_level"

      - record: job:http_request_duration:p90
        expr: |
          histogram_quantile(0.90, 
            sum by (job, le) (rate(http_request_duration_seconds_bucket[5m]))
          )
        labels:
          rule_type: "application_level"

      - record: job:http_request_duration:p95
        expr: |
          histogram_quantile(0.95, 
            sum by (job, le) (rate(http_request_duration_seconds_bucket[5m]))
          )
        labels:
          rule_type: "application_level"

      - record: job:http_request_duration:p99
        expr: |
          histogram_quantile(0.99, 
            sum by (job, le) (rate(http_request_duration_seconds_bucket[5m]))
          )
        labels:
          rule_type: "application_level"

      - record: job:http_request_duration:mean5m
        expr: |
          sum by (job) (rate(http_request_duration_seconds_sum[5m])) /
          sum by (job) (rate(http_request_duration_seconds_count[5m]))
        labels:
          rule_type: "application_level"

      {{#if runtime}}
      {{#eq runtime 'node'}}
      # Node.js Specific Rules
      - record: job:nodejs_heap_utilisation:ratio
        expr: |
          avg by (job) (nodejs_heap_size_used_bytes / nodejs_heap_size_total_bytes)
        labels:
          rule_type: "application_level"
          runtime: "nodejs"

      - record: job:nodejs_external_memory:bytes
        expr: |
          avg by (job) (nodejs_external_memory_bytes)
        labels:
          rule_type: "application_level"
          runtime: "nodejs"

      - record: job:nodejs_eventloop_lag:seconds
        expr: |
          avg by (job) (nodejs_eventloop_lag_seconds)
        labels:
          rule_type: "application_level"
          runtime: "nodejs"

      - record: job:nodejs_active_handles:count
        expr: |
          avg by (job) (nodejs_active_handles)
        labels:
          rule_type: "application_level"
          runtime: "nodejs"

      - record: job:nodejs_gc_duration:rate5m
        expr: |
          sum by (job, kind) (rate(nodejs_gc_duration_seconds_sum[5m]))
        labels:
          rule_type: "application_level"
          runtime: "nodejs"
      {{/eq}}
      {{/if}}

  - name: "{{projectName}}.sli.rules"
    interval: 60s
    rules:
      # Service Level Indicator (SLI) Rules for SLO monitoring
      
      # Availability SLI
      - record: sli:availability:ratio1h
        expr: |
          avg_over_time(up{job="{{projectName}}"}[1h])
        labels:
          sli_type: "availability"
          service: "{{projectName}}"

      - record: sli:availability:ratio24h
        expr: |
          avg_over_time(up{job="{{projectName}}"}[24h])
        labels:
          sli_type: "availability"
          service: "{{projectName}}"

      - record: sli:availability:ratio7d
        expr: |
          avg_over_time(up{job="{{projectName}}"}[7d])
        labels:
          sli_type: "availability"
          service: "{{projectName}}"

      # Latency SLI (percentage of requests below threshold)
      - record: sli:latency:good_ratio5m
        expr: |
          sum(rate(http_request_duration_seconds_bucket{le="0.5", job="{{projectName}}"}[5m])) /
          sum(rate(http_request_duration_seconds_count{job="{{projectName}}"}[5m]))
        labels:
          sli_type: "latency"
          service: "{{projectName}}"
          threshold: "500ms"

      - record: sli:latency:good_ratio1h
        expr: |
          sum(rate(http_request_duration_seconds_bucket{le="0.5", job="{{projectName}}"}[1h])) /
          sum(rate(http_request_duration_seconds_count{job="{{projectName}}"}[1h]))
        labels:
          sli_type: "latency"
          service: "{{projectName}}"
          threshold: "500ms"

      - record: sli:latency:good_ratio24h
        expr: |
          sum(rate(http_request_duration_seconds_bucket{le="0.5", job="{{projectName}}"}[24h])) /
          sum(rate(http_request_duration_seconds_count{job="{{projectName}}"}[24h]))
        labels:
          sli_type: "latency"
          service: "{{projectName}}"
          threshold: "500ms"

      # Error Rate SLI (percentage of successful requests)
      - record: sli:error_rate:good_ratio5m
        expr: |
          sum(rate(http_requests_total{status!~"5..", job="{{projectName}}"}[5m])) /
          sum(rate(http_requests_total{job="{{projectName}}"}[5m]))
        labels:
          sli_type: "error_rate"
          service: "{{projectName}}"

      - record: sli:error_rate:good_ratio1h
        expr: |
          sum(rate(http_requests_total{status!~"5..", job="{{projectName}}"}[1h])) /
          sum(rate(http_requests_total{job="{{projectName}}"}[1h]))
        labels:
          sli_type: "error_rate"
          service: "{{projectName}}"

      - record: sli:error_rate:good_ratio24h
        expr: |
          sum(rate(http_requests_total{status!~"5..", job="{{projectName}}"}[24h])) /
          sum(rate(http_requests_total{job="{{projectName}}"}[24h]))
        labels:
          sli_type: "error_rate"
          service: "{{projectName}}"

      # Error Budget Burn Rate
      - record: sli:error_budget_burn_rate:1h
        expr: |
          (1 - sli:availability:ratio1h{service="{{projectName}}"}) / (1 - 0.999)
        labels:
          sli_type: "error_budget"
          service: "{{projectName}}"
          slo_target: "99.9%"

      - record: sli:error_budget_burn_rate:6h
        expr: |
          (1 - avg_over_time(sli:availability:ratio1h{service="{{projectName}}"}[6h])) / (1 - 0.999)
        labels:
          sli_type: "error_budget"
          service: "{{projectName}}"
          slo_target: "99.9%"

  {{#if kubernetes}}
  - name: "{{projectName}}.kubernetes.rules"
    interval: 30s
    rules:
      # Kubernetes Resource Rules
      
      # Pod Resource Utilization
      - record: namespace:container_cpu_usage:rate5m
        expr: |
          sum by (namespace, pod, container) (
            rate(container_cpu_usage_seconds_total{container!="POD", container!=""}[5m])
          )
        labels:
          rule_type: "kubernetes"

      - record: namespace:container_memory_usage:bytes
        expr: |
          sum by (namespace, pod, container) (
            container_memory_working_set_bytes{container!="POD", container!=""}
          )
        labels:
          rule_type: "kubernetes"

      # Namespace Aggregations
      - record: namespace:pod_cpu:sum_rate5m
        expr: |
          sum by (namespace) (
            namespace:container_cpu_usage:rate5m
          )
        labels:
          rule_type: "kubernetes"

      - record: namespace:pod_memory:sum_bytes
        expr: |
          sum by (namespace) (
            namespace:container_memory_usage:bytes
          )
        labels:
          rule_type: "kubernetes"

      # HPA Scaling Metrics
      - record: namespace:hpa_desired_replicas:current
        expr: |
          kube_hpa_spec_target_metric{metric_name="cpu", metric_target_type="utilization"}
        labels:
          rule_type: "kubernetes"

      - record: namespace:hpa_current_replicas:ratio
        expr: |
          kube_hpa_status_current_replicas / kube_hpa_spec_max_replicas
        labels:
          rule_type: "kubernetes"
  {{/if}}

  {{#if features.includes('custom-metrics')}}
  - name: "{{projectName}}.custom.rules"
    interval: 30s
    rules:
      # Custom Business Logic Rules
      {{#each prometheus.recordingRules}}
      - record: {{record}}
        expr: {{expr}}
        {{#if labels}}
        labels:
          {{#each labels}}
          {{@key}}: "{{this}}"
          {{/each}}
          rule_type: "custom"
          service: "{{../projectName}}"
        {{else}}
        labels:
          rule_type: "custom"
          service: "{{../projectName}}"
        {{/if}}
      {{/each}}
  {{/if}}

  - name: "{{projectName}}.aggregation.rules"
    interval: 60s
    rules:
      # High-level aggregation rules for dashboards and long-term storage
      
      # Service-level Aggregations
      - record: service:request_rate:rate5m
        expr: |
          sum(job:http_requests:rate5m{job="{{projectName}}"})
        labels:
          service: "{{projectName}}"
          aggregation_level: "service"

      - record: service:error_rate:ratio5m
        expr: |
          avg(job:http_requests_error_rate:ratio5m{job="{{projectName}}"})
        labels:
          service: "{{projectName}}"
          aggregation_level: "service"

      - record: service:response_time:p95
        expr: |
          avg(job:http_request_duration:p95{job="{{projectName}}"})
        labels:
          service: "{{projectName}}"
          aggregation_level: "service"

      # Infrastructure Aggregations
      - record: service:cpu_utilization:avg
        expr: |
          avg(instance:node_cpu_utilisation:rate5m)
        labels:
          service: "{{projectName}}"
          aggregation_level: "infrastructure"

      - record: service:memory_utilization:avg
        expr: |
          avg(instance:node_memory_utilisation:ratio)
        labels:
          service: "{{projectName}}"
          aggregation_level: "infrastructure"

      - record: service:disk_utilization:avg
        expr: |
          avg(100 - instance:node_filesystem_avail_percent{mountpoint="/"})
        labels:
          service: "{{projectName}}"
          aggregation_level: "infrastructure"

      # Multi-window SLI Rules for alerting
      - record: service:sli_error_budget_remaining:ratio30d
        expr: |
          1 - (
            (1 - avg_over_time(sli:availability:ratio24h{service="{{projectName}}"}[30d])) /
            (1 - 0.999)
          )
        labels:
          service: "{{projectName}}"
          sli_type: "error_budget"
          window: "30d"