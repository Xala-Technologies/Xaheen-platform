/**
 * Feedback Database Schema
 * Database schema for storing continuous learning feedback data
 * Generated with Xaheen CLI - Continuous Learning System
 */

{{#if (eq database "postgresql")}}
-- Feedback table for storing developer feedback
CREATE TABLE IF NOT EXISTS feedback (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  suggestion_id UUID NOT NULL,
  user_id UUID{{#if feedbackCollection.anonymization}} NULL{{else}} NOT NULL{{/if}},
  action VARCHAR(20) NOT NULL CHECK (action IN ('accepted', 'rejected', 'modified')),
  reason TEXT,
  modified_code TEXT,
  confidence DECIMAL(3,2) NOT NULL CHECK (confidence >= 0 AND confidence <= 1),
  
  -- Context information
  file_type VARCHAR(50) NOT NULL,
  project_type VARCHAR(100) NOT NULL,
  code_complexity INTEGER NOT NULL CHECK (code_complexity >= 1 AND code_complexity <= 5),
  user_experience VARCHAR(20) NOT NULL CHECK (user_experience IN ('junior', 'mid', 'senior', 'expert')),
  
  -- Metadata (JSON column for flexible data)
  metadata JSONB DEFAULT '{}',
  
  -- Timestamps
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  
  -- Partitioning support
  {{#if (eq feedbackCollection.retention.partitioning "time")}}
  partition_date DATE GENERATED ALWAYS AS (DATE(created_at)) STORED,
  {{else if (eq feedbackCollection.retention.partitioning "user")}}
  partition_user_hash INTEGER GENERATED ALWAYS AS (ABS(HASHTEXT(user_id::TEXT)) % 10) STORED,
  {{/if}}
  
  -- Indexes
  CONSTRAINT feedback_suggestion_user_unique UNIQUE (suggestion_id, user_id, created_at)
);

-- Create indexes for performance
CREATE INDEX idx_feedback_created_at ON feedback(created_at DESC);
CREATE INDEX idx_feedback_action ON feedback(action);
CREATE INDEX idx_feedback_user_experience ON feedback(user_experience);
CREATE INDEX idx_feedback_file_type ON feedback(file_type);
CREATE INDEX idx_feedback_confidence ON feedback(confidence);
CREATE INDEX idx_feedback_suggestion_id ON feedback(suggestion_id);
{{#unless feedbackCollection.anonymization}}
CREATE INDEX idx_feedback_user_id ON feedback(user_id);
{{/unless}}

-- GIN index for metadata JSONB queries
CREATE INDEX idx_feedback_metadata ON feedback USING GIN(metadata);

-- Composite indexes for common queries
CREATE INDEX idx_feedback_analytics ON feedback(action, created_at, user_experience);
CREATE INDEX idx_feedback_trends ON feedback(created_at, action, confidence);

{{#if (eq feedbackCollection.retention.partitioning "time")}}
-- Partitioning by date (monthly partitions)
CREATE TABLE feedback_y2024m01 PARTITION OF feedback
  FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
CREATE TABLE feedback_y2024m02 PARTITION OF feedback
  FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');
-- Add more partitions as needed
{{/if}}

-- Model versions table
CREATE TABLE IF NOT EXISTS model_versions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  model_id VARCHAR(100) NOT NULL,
  version_number VARCHAR(50) NOT NULL,
  version_strategy VARCHAR(20) NOT NULL CHECK (version_strategy IN ('semantic', 'timestamp', 'incremental')),
  status VARCHAR(20) NOT NULL DEFAULT 'inactive' CHECK (status IN ('deploying', 'active', 'inactive', 'failed', 'canary')),
  
  -- Version metadata
  description TEXT,
  tags TEXT[],
  semantic_version VARCHAR(20),
  
  -- Storage information
  storage_provider VARCHAR(20) NOT NULL,
  storage_path TEXT NOT NULL,
  model_size_bytes BIGINT,
  
  -- Performance metrics
  accuracy DECIMAL(5,4),
  precision_score DECIMAL(5,4),
  recall_score DECIMAL(5,4),
  f1_score DECIMAL(5,4),
  response_time_ms INTEGER,
  throughput_rps INTEGER,
  
  -- Deployment information
  deployed_at TIMESTAMP WITH TIME ZONE,
  deployed_by UUID,
  canary_percentage INTEGER DEFAULT 0 CHECK (canary_percentage >= 0 AND canary_percentage <= 100),
  
  -- Rollback information
  rolled_back_at TIMESTAMP WITH TIME ZONE,
  rollback_reason TEXT,
  rollback_target_version UUID REFERENCES model_versions(id),
  
  -- Timestamps
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  
  CONSTRAINT model_version_unique UNIQUE (model_id, version_number)
);

-- Indexes for model versions
CREATE INDEX idx_model_versions_model_id ON model_versions(model_id);
CREATE INDEX idx_model_versions_status ON model_versions(status);
CREATE INDEX idx_model_versions_deployed_at ON model_versions(deployed_at DESC);
CREATE INDEX idx_model_versions_performance ON model_versions(accuracy DESC, response_time_ms ASC);

-- Performance metrics table for detailed tracking
CREATE TABLE IF NOT EXISTS performance_metrics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  model_version_id UUID NOT NULL REFERENCES model_versions(id) ON DELETE CASCADE,
  metric_type VARCHAR(50) NOT NULL,
  metric_value DECIMAL(10,6) NOT NULL,
  measurement_timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  
  -- Context for the measurement
  context JSONB DEFAULT '{}',
  
  -- Aggregation period (for pre-aggregated metrics)
  aggregation_period VARCHAR(10) CHECK (aggregation_period IN ('minute', 'hour', 'day', 'week', 'month')),
  period_start TIMESTAMP WITH TIME ZONE,
  period_end TIMESTAMP WITH TIME ZONE,
  
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Indexes for performance metrics
CREATE INDEX idx_performance_metrics_version ON performance_metrics(model_version_id);
CREATE INDEX idx_performance_metrics_type ON performance_metrics(metric_type);
CREATE INDEX idx_performance_metrics_timestamp ON performance_metrics(measurement_timestamp DESC);
CREATE INDEX idx_performance_metrics_period ON performance_metrics(aggregation_period, period_start, period_end);

{{#if abTesting.enabled}}
-- A/B testing experiments table
CREATE TABLE IF NOT EXISTS ab_experiments (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name VARCHAR(200) NOT NULL,
  description TEXT,
  status VARCHAR(20) NOT NULL DEFAULT 'draft' CHECK (status IN ('draft', 'running', 'completed', 'paused', 'cancelled')),
  
  -- Experiment configuration
  traffic_allocation INTEGER NOT NULL DEFAULT {{abTesting.trafficAllocation}} CHECK (traffic_allocation >= 0 AND traffic_allocation <= 100),
  split_strategy VARCHAR(20) NOT NULL DEFAULT '{{abTesting.splitStrategy}}' CHECK (split_strategy IN ('random', 'user-based', 'feature-based')),
  minimum_sample_size INTEGER NOT NULL DEFAULT {{abTesting.minimumSampleSize}},
  statistical_significance DECIMAL(3,2) NOT NULL DEFAULT {{abTesting.statisticalSignificance}},
  duration_days INTEGER DEFAULT {{abTesting.duration}},
  
  -- Target metrics to track
  target_metrics TEXT[] NOT NULL,
  
  -- Timestamps
  start_date TIMESTAMP WITH TIME ZONE,
  end_date TIMESTAMP WITH TIME ZONE,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  
  -- Results
  winner_variant_id UUID,
  confidence_level DECIMAL(5,2),
  results JSONB DEFAULT '{}'
);

-- A/B test variants table
CREATE TABLE IF NOT EXISTS ab_variants (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  experiment_id UUID NOT NULL REFERENCES ab_experiments(id) ON DELETE CASCADE,
  name VARCHAR(100) NOT NULL,
  model_version_id UUID NOT NULL REFERENCES model_versions(id),
  traffic_percentage INTEGER NOT NULL CHECK (traffic_percentage >= 0 AND traffic_percentage <= 100),
  is_control BOOLEAN NOT NULL DEFAULT FALSE,
  
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  
  CONSTRAINT ab_variant_experiment_unique UNIQUE (experiment_id, name)
);

-- A/B test results table
CREATE TABLE IF NOT EXISTS ab_results (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  experiment_id UUID NOT NULL REFERENCES ab_experiments(id) ON DELETE CASCADE,
  variant_id UUID NOT NULL REFERENCES ab_variants(id) ON DELETE CASCADE,
  
  -- User assignment (for user-based splitting)
  user_id UUID,
  session_id VARCHAR(100),
  
  -- Interaction data
  feedback_id UUID REFERENCES feedback(id),
  metric_type VARCHAR(50) NOT NULL,
  metric_value DECIMAL(10,6) NOT NULL,
  
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Indexes for A/B testing
CREATE INDEX idx_ab_experiments_status ON ab_experiments(status);
CREATE INDEX idx_ab_experiments_dates ON ab_experiments(start_date, end_date);
CREATE INDEX idx_ab_variants_experiment ON ab_variants(experiment_id);
CREATE INDEX idx_ab_results_experiment ON ab_results(experiment_id);
CREATE INDEX idx_ab_results_variant ON ab_results(variant_id);
CREATE INDEX idx_ab_results_user ON ab_results(user_id);
{{/if}}

-- User analytics table (if not anonymized)
{{#unless feedbackCollection.anonymization}}
CREATE TABLE IF NOT EXISTS user_analytics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL,
  
  -- User characteristics
  experience_level VARCHAR(20) CHECK (experience_level IN ('junior', 'mid', 'senior', 'expert')),
  primary_language VARCHAR(50),
  project_types TEXT[],
  
  -- Aggregated metrics
  total_feedback_count INTEGER DEFAULT 0,
  acceptance_rate DECIMAL(5,4),
  rejection_rate DECIMAL(5,4),
  modification_rate DECIMAL(5,4),
  avg_confidence DECIMAL(5,4),
  
  -- Behavior patterns
  most_active_hours INTEGER[], -- Hours of day (0-23)
  preferred_suggestion_types TEXT[],
  avg_response_time_seconds INTEGER,
  
  -- Timestamps
  first_interaction TIMESTAMP WITH TIME ZONE,
  last_interaction TIMESTAMP WITH TIME ZONE,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  
  CONSTRAINT user_analytics_unique UNIQUE (user_id)
);

-- Index for user analytics
CREATE INDEX idx_user_analytics_user_id ON user_analytics(user_id);
CREATE INDEX idx_user_analytics_experience ON user_analytics(experience_level);
CREATE INDEX idx_user_analytics_acceptance_rate ON user_analytics(acceptance_rate DESC);
{{/unless}}

{{#if (eq feedbackCollection.retention.archiving true)}}
-- Archived feedback table for long-term storage
CREATE TABLE IF NOT EXISTS feedback_archive (
  id UUID PRIMARY KEY,
  suggestion_id UUID NOT NULL,
  user_id UUID,
  action VARCHAR(20) NOT NULL,
  reason TEXT,
  confidence DECIMAL(3,2) NOT NULL,
  
  -- Compressed context data
  context_summary JSONB,
  
  -- Original timestamps
  original_created_at TIMESTAMP WITH TIME ZONE NOT NULL,
  archived_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  
  -- Archival metadata
  archive_reason VARCHAR(50) DEFAULT 'retention_policy',
  {{#if feedbackCollection.retention.compression}}
  compressed_data BYTEA, -- Compressed original data
  compression_ratio DECIMAL(5,2),
  {{/if}}
  
  CONSTRAINT feedback_archive_unique UNIQUE (id, original_created_at)
);

-- Partitioning for archive table by year
CREATE TABLE feedback_archive_2024 PARTITION OF feedback_archive
  FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');
CREATE TABLE feedback_archive_2025 PARTITION OF feedback_archive
  FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');
{{/if}}

-- Create triggers for updating timestamps
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ language 'plpgsql';

CREATE TRIGGER update_feedback_updated_at BEFORE UPDATE ON feedback
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_model_versions_updated_at BEFORE UPDATE ON model_versions
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

{{#if abTesting.enabled}}
CREATE TRIGGER update_ab_experiments_updated_at BEFORE UPDATE ON ab_experiments
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
{{/if}}

{{#unless feedbackCollection.anonymization}}
CREATE TRIGGER update_user_analytics_updated_at BEFORE UPDATE ON user_analytics
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
{{/unless}}

{{#if (eq feedbackCollection.retention.archiving true)}}
-- Function to archive old feedback data
CREATE OR REPLACE FUNCTION archive_old_feedback(retention_days INTEGER DEFAULT {{feedbackCollection.retention.duration}})
RETURNS INTEGER AS $$
DECLARE
    archived_count INTEGER;
    cutoff_date TIMESTAMP WITH TIME ZONE;
BEGIN
    cutoff_date := NOW() - INTERVAL '1 day' * retention_days;
    
    -- Move old records to archive
    WITH moved_rows AS (
        DELETE FROM feedback 
        WHERE created_at < cutoff_date
        RETURNING *
    )
    INSERT INTO feedback_archive (
        id, suggestion_id, user_id, action, reason, confidence,
        context_summary, original_created_at, archive_reason
        {{#if feedbackCollection.retention.compression}}, compressed_data, compression_ratio{{/if}}
    )
    SELECT 
        id, suggestion_id, user_id, action, reason, confidence,
        jsonb_build_object(
            'file_type', file_type,
            'project_type', project_type,
            'code_complexity', code_complexity,
            'user_experience', user_experience
        ),
        created_at,
        'retention_policy'
        {{#if feedbackCollection.retention.compression}}
        , compress(row_to_json(moved_rows)::text::bytea)
        , 0.5 -- Placeholder compression ratio
        {{/if}}
    FROM moved_rows;
    
    GET DIAGNOSTICS archived_count = ROW_COUNT;
    
    RETURN archived_count;
END;
$$ LANGUAGE plpgsql;
{{/if}}

-- Create materialized view for common analytics queries
CREATE MATERIALIZED VIEW feedback_analytics_daily AS
SELECT 
    DATE(created_at) as date,
    action,
    user_experience,
    file_type,
    COUNT(*) as count,
    AVG(confidence) as avg_confidence,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY confidence) as median_confidence
FROM feedback
WHERE created_at >= CURRENT_DATE - INTERVAL '90 days'
GROUP BY DATE(created_at), action, user_experience, file_type;

-- Index for the materialized view
CREATE INDEX idx_feedback_analytics_daily_date ON feedback_analytics_daily(date DESC);
CREATE INDEX idx_feedback_analytics_daily_action ON feedback_analytics_daily(action);

-- Refresh the materialized view daily
-- This would be called by a scheduled job
-- REFRESH MATERIALIZED VIEW CONCURRENTLY feedback_analytics_daily;

{{else if (eq database "mysql")}}
-- MySQL schema equivalent
-- Similar structure adapted for MySQL syntax

{{else if (eq database "mongodb")}}
-- MongoDB collection schemas (as JavaScript)
/*
// Feedback collection
db.createCollection("feedback", {
  validator: {
    $jsonSchema: {
      bsonType: "object",
      required: ["suggestionId", "action", "confidence", "context"],
      properties: {
        suggestionId: { bsonType: "string" },
        userId: { bsonType: ["string", "null"] },
        action: { enum: ["accepted", "rejected", "modified"] },
        reason: { bsonType: ["string", "null"] },
        modifiedCode: { bsonType: ["string", "null"] },
        confidence: { bsonType: "double", minimum: 0, maximum: 1 },
        context: {
          bsonType: "object",
          required: ["fileType", "projectType", "codeComplexity", "userExperience"],
          properties: {
            fileType: { bsonType: "string" },
            projectType: { bsonType: "string" },
            codeComplexity: { bsonType: "int", minimum: 1, maximum: 5 },
            userExperience: { enum: ["junior", "mid", "senior", "expert"] }
          }
        },
        metadata: { bsonType: ["object", "null"] },
        createdAt: { bsonType: "date" },
        updatedAt: { bsonType: "date" }
      }
    }
  }
});

// Create indexes
db.feedback.createIndex({ "createdAt": -1 });
db.feedback.createIndex({ "action": 1 });
db.feedback.createIndex({ "suggestionId": 1 });
db.feedback.createIndex({ "context.userExperience": 1 });
db.feedback.createIndex({ "context.fileType": 1 });
db.feedback.createIndex({ "confidence": 1 });
{{#unless feedbackCollection.anonymization}}
db.feedback.createIndex({ "userId": 1 });
{{/unless}}

// Compound indexes for analytics
db.feedback.createIndex({ 
  "action": 1, 
  "createdAt": -1, 
  "context.userExperience": 1 
});
*/

{{else if (eq database "sqlite")}}
-- SQLite schema (simplified version)
-- Similar structure adapted for SQLite syntax with appropriate data types

{{/if}}

-- Common views and functions (database-agnostic concepts)
/*
Analytics Views:
1. Daily feedback summary
2. User experience breakdown
3. Model performance trends
4. Acceptance rates by file type
5. Confidence distribution analysis

Stored Procedures/Functions:
1. Calculate acceptance rates
2. Generate trend analysis
3. Export feedback data
4. Archive old records
5. Update user analytics
*/