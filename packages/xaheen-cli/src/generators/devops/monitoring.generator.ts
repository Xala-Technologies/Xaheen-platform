// Monitoring & Observability Generator for Story 4.3
// Generated by Xaheen CLI with Prometheus 3.0, Grafana, and OpenTelemetry

import { BaseGenerator } from '../base.generator';
import { TemplateManager } from '../../services/templates/template-loader';
import { ProjectAnalyzer } from '../../services/analysis/project-analyzer';
import { writeFileSync, mkdirSync, existsSync } from 'fs';
import { join } from 'path';

export interface MonitoringGeneratorOptions {
  readonly projectName: string;
  readonly projectType: 'web' | 'api' | 'microservice' | 'fullstack';
  readonly runtime: 'node' | 'python' | 'go' | 'java' | 'dotnet';
  readonly outputDir?: string;
  readonly features: readonly MonitoringFeature[];
  readonly environment: 'development' | 'staging' | 'production';
  readonly prometheus: PrometheusConfig;
  readonly grafana: GrafanaConfig;
  readonly opentelemetry: OpenTelemetryConfig;
  readonly logging: LoggingConfig;
  readonly alerting: AlertingConfig;
  readonly kubernetes?: KubernetesMonitoringConfig;
}

export type MonitoringFeature = 
  | 'prometheus'
  | 'grafana' 
  | 'opentelemetry'
  | 'jaeger'
  | 'loki'
  | 'tempo'
  | 'alertmanager'
  | 'node-exporter'
  | 'cadvisor'
  | 'blackbox-exporter'
  | 'otel-collector'
  | 'custom-metrics'
  | 'distributed-tracing'
  | 'log-correlation'
  | 'sli-slo'
  | 'error-tracking';

export interface PrometheusConfig {
  readonly version: string;
  readonly retentionTime: string;
  readonly scrapeInterval: string;
  readonly evaluationInterval: string;
  readonly enableRemoteWrite: boolean;
  readonly remoteWriteConfig?: RemoteWriteConfig;
  readonly alertingRules: readonly AlertRule[];
  readonly recordingRules: readonly RecordingRule[];
  readonly serviceDiscovery: ServiceDiscoveryConfig;
}

export interface RemoteWriteConfig {
  readonly url: string;
  readonly headers?: Record<string, string>;
  readonly basicAuth?: {
    readonly username: string;
    readonly password: string;
  };
}

export interface AlertRule {
  readonly name: string;
  readonly expr: string;
  readonly for: string;
  readonly severity: 'critical' | 'warning' | 'info';
  readonly summary: string;
  readonly description: string;
  readonly annotations?: Record<string, string>;
  readonly labels?: Record<string, string>;
}

export interface RecordingRule {
  readonly record: string;
  readonly expr: string;
  readonly labels?: Record<string, string>;
}

export interface ServiceDiscoveryConfig {
  readonly kubernetes: boolean;
  readonly consul: boolean;
  readonly ec2: boolean;
  readonly staticConfigs: readonly StaticConfig[];
}

export interface StaticConfig {
  readonly jobName: string;
  readonly targets: readonly string[];
  readonly labels?: Record<string, string>;
  readonly metricsPath?: string;
  readonly scrapeInterval?: string;
}

export interface GrafanaConfig {
  readonly version: string;
  readonly adminPassword: string;
  readonly datasources: readonly DataSource[];
  readonly dashboards: readonly Dashboard[];
  readonly plugins: readonly string[];
  readonly provisioning: ProvisioningConfig;
}

export interface DataSource {
  readonly name: string;
  readonly type: 'prometheus' | 'loki' | 'tempo' | 'jaeger' | 'elasticsearch';
  readonly url: string;
  readonly isDefault: boolean;
  readonly access: 'proxy' | 'direct';
  readonly basicAuth?: boolean;
  readonly jsonData?: Record<string, any>;
}

export interface Dashboard {
  readonly name: string;
  readonly uid: string;
  readonly tags: readonly string[];
  readonly panels: readonly Panel[];
  readonly variables: readonly Variable[];
  readonly time: TimeRange;
  readonly refresh: string;
}

export interface Panel {
  readonly id: number;
  readonly title: string;
  readonly type: 'graph' | 'stat' | 'gauge' | 'table' | 'heatmap' | 'logs';
  readonly targets: readonly Target[];
  readonly gridPos: GridPosition;
  readonly options?: Record<string, any>;
  readonly fieldConfig?: FieldConfig;
}

export interface Target {
  readonly expr: string;
  readonly legendFormat?: string;
  readonly refId: string;
  readonly interval?: string;
}

export interface GridPosition {
  readonly h: number;
  readonly w: number;
  readonly x: number;
  readonly y: number;
}

export interface FieldConfig {
  readonly defaults: {
    readonly unit?: string;
    readonly min?: number;
    readonly max?: number;
    readonly thresholds?: Threshold[];
  };
}

export interface Threshold {
  readonly color: string;
  readonly value: number;
}

export interface Variable {
  readonly name: string;
  readonly type: 'query' | 'interval' | 'constant' | 'custom';
  readonly query?: string;
  readonly options?: readonly string[];
  readonly current?: {
    readonly text: string;
    readonly value: string;
  };
}

export interface TimeRange {
  readonly from: string;
  readonly to: string;
}

export interface ProvisioningConfig {
  readonly datasources: boolean;
  readonly dashboards: boolean;
  readonly notifiers: boolean;
}

export interface OpenTelemetryConfig {
  readonly version: string;
  readonly collector: CollectorConfig;
  readonly instrumentation: InstrumentationConfig;
  readonly exporters: readonly ExporterConfig[];
  readonly processors: readonly ProcessorConfig[];
  readonly extensions: readonly string[];
}

export interface CollectorConfig {
  readonly mode: 'agent' | 'gateway';
  readonly receivers: readonly ReceiverConfig[];
  readonly processors: readonly string[];
  readonly exporters: readonly string[];
  readonly service: ServiceConfig;
}

export interface ReceiverConfig {
  readonly name: string;
  readonly config: Record<string, any>;
}

export interface ExporterConfig {
  readonly name: string;
  readonly type: 'otlp' | 'prometheus' | 'jaeger' | 'zipkin' | 'logging';
  readonly endpoint?: string;
  readonly config: Record<string, any>;
}

export interface ProcessorConfig {
  readonly name: string;
  readonly type: 'batch' | 'memory_limiter' | 'resource' | 'attributes' | 'span';
  readonly config: Record<string, any>;
}

export interface ServiceConfig {
  readonly pipelines: {
    readonly traces?: Pipeline;
    readonly metrics?: Pipeline;
    readonly logs?: Pipeline;
  };
  readonly extensions: readonly string[];
}

export interface Pipeline {
  readonly receivers: readonly string[];
  readonly processors: readonly string[];
  readonly exporters: readonly string[];
}

export interface InstrumentationConfig {
  readonly auto: boolean;
  readonly manual: boolean;
  readonly libraries: readonly string[];
  readonly samplingRatio: number;
  readonly resourceAttributes: Record<string, string>;
}

export interface LoggingConfig {
  readonly structured: boolean;
  readonly level: 'debug' | 'info' | 'warn' | 'error';
  readonly format: 'json' | 'text';
  readonly correlation: CorrelationConfig;
  readonly aggregation: AggregationConfig;
}

export interface CorrelationConfig {
  readonly enabled: boolean;
  readonly traceIdField: string;
  readonly spanIdField: string;
  readonly serviceNameField: string;
}

export interface AggregationConfig {
  readonly loki: LokiConfig;
  readonly elasticsearch: ElasticsearchConfig;
}

export interface LokiConfig {
  readonly enabled: boolean;
  readonly url: string;
  readonly labels: Record<string, string>;
  readonly batchSize: number;
  readonly batchWait: string;
}

export interface ElasticsearchConfig {
  readonly enabled: boolean;
  readonly url: string;
  readonly index: string;
  readonly mapping: Record<string, any>;
}

export interface AlertingConfig {
  readonly alertmanager: AlertmanagerConfig;
  readonly channels: readonly NotificationChannel[];
  readonly silences: readonly Silence[];
}

export interface AlertmanagerConfig {
  readonly version: string;
  readonly route: Route;
  readonly receivers: readonly Receiver[];
  readonly inhibitRules: readonly InhibitRule[];
}

export interface Route {
  readonly groupBy: readonly string[];
  readonly groupWait: string;
  readonly groupInterval: string;
  readonly repeatInterval: string;
  readonly receiver: string;
  readonly routes?: readonly Route[];
}

export interface Receiver {
  readonly name: string;
  readonly webhookConfigs?: readonly WebhookConfig[];
  readonly emailConfigs?: readonly EmailConfig[];
  readonly slackConfigs?: readonly SlackConfig[];
  readonly pagerdutyConfigs?: readonly PagerDutyConfig[];
}

export interface WebhookConfig {
  readonly url: string;
  readonly httpConfig?: HttpConfig;
}

export interface EmailConfig {
  readonly to: string;
  readonly from: string;
  readonly subject: string;
  readonly body: string;
}

export interface SlackConfig {
  readonly apiUrl: string;
  readonly channel: string;
  readonly title: string;
  readonly text: string;
}

export interface PagerDutyConfig {
  readonly routingKey: string;
  readonly severity: string;
  readonly description: string;
}

export interface HttpConfig {
  readonly basicAuth?: {
    readonly username: string;
    readonly password: string;
  };
  readonly bearerToken?: string;
  readonly headers?: Record<string, string>;
}

export interface InhibitRule {
  readonly sourceMatch: Record<string, string>;
  readonly targetMatch: Record<string, string>;
  readonly equal: readonly string[];
}

export interface NotificationChannel {
  readonly name: string;
  readonly type: 'slack' | 'email' | 'webhook' | 'pagerduty' | 'teams';
  readonly settings: Record<string, any>;
}

export interface Silence {
  readonly matchers: readonly Matcher[];
  readonly startsAt: string;
  readonly endsAt: string;
  readonly createdBy: string;
  readonly comment: string;
}

export interface Matcher {
  readonly name: string;
  readonly value: string;
  readonly isRegex: boolean;
}

export interface KubernetesMonitoringConfig {
  readonly namespace: string;
  readonly serviceMonitors: boolean;
  readonly podMonitors: boolean;
  readonly nodeExporter: boolean;
  readonly kubeStateMetrics: boolean;
  readonly cadvisor: boolean;
}

export class MonitoringGenerator extends BaseGenerator<MonitoringGeneratorOptions> {
  private readonly templateManager: TemplateManager;
  private readonly analyzer: ProjectAnalyzer;
  private readonly DEFAULT_OUTPUT_DIR = './monitoring';

  constructor() {
    super();
    this.templateManager = new TemplateManager();
    this.analyzer = new ProjectAnalyzer();
  }

  async generate(options: MonitoringGeneratorOptions): Promise<void> {
    try {
      await this.validateOptions(options);
      
      this.logger.info(`Generating monitoring stack for ${options.projectName}...`);
      
      const outputDir = options.outputDir || this.DEFAULT_OUTPUT_DIR;
      this.ensureDirectoryExists(outputDir);
      
      // Generate Prometheus 3.0 configuration
      if (options.features.includes('prometheus')) {
        await this.generatePrometheusConfig(options, outputDir);
      }
      
      // Generate Grafana configuration
      if (options.features.includes('grafana')) {
        await this.generateGrafanaConfig(options, outputDir);
      }
      
      // Generate OpenTelemetry configuration
      if (options.features.includes('opentelemetry')) {
        await this.generateOpenTelemetryConfig(options, outputDir);
      }
      
      // Generate Loki configuration
      if (options.features.includes('loki')) {
        await this.generateLokiConfig(options, outputDir);
      }
      
      // Generate Tempo configuration
      if (options.features.includes('tempo')) {
        await this.generateTempoConfig(options, outputDir);
      }
      
      // Generate Jaeger configuration
      if (options.features.includes('jaeger')) {
        await this.generateJaegerConfig(options, outputDir);
      }
      
      // Generate Alertmanager configuration
      if (options.features.includes('alertmanager')) {
        await this.generateAlertmanagerConfig(options, outputDir);
      }
      
      // Generate exporters
      if (options.features.includes('node-exporter')) {
        await this.generateNodeExporterConfig(options, outputDir);
      }
      
      if (options.features.includes('blackbox-exporter')) {
        await this.generateBlackboxExporterConfig(options, outputDir);
      }
      
      // Generate application instrumentation
      await this.generateApplicationInstrumentation(options, outputDir);
      
      // Generate Docker Compose for local development
      await this.generateDockerCompose(options, outputDir);
      
      // Generate Kubernetes manifests if enabled
      if (options.kubernetes) {
        await this.generateKubernetesManifests(options, outputDir);
      }
      
      // Generate deployment scripts
      await this.generateDeploymentScripts(options, outputDir);
      
      this.logger.success(`Monitoring stack generated successfully in ${outputDir}`);
      
    } catch (error) {
      this.logger.error('Failed to generate monitoring configuration', error);
      throw error;
    }
  }

  protected async validateOptions(options: MonitoringGeneratorOptions): Promise<void> {
    if (!options.projectName) {
      throw new Error('Project name is required');
    }
    
    if (!options.features || options.features.length === 0) {
      throw new Error('At least one monitoring feature must be specified');
    }
    
    if (options.features.includes('prometheus') && !options.prometheus) {
      throw new Error('Prometheus configuration is required when Prometheus feature is enabled');
    }
    
    if (options.features.includes('grafana') && !options.grafana) {
      throw new Error('Grafana configuration is required when Grafana feature is enabled');
    }
    
    if (options.features.includes('opentelemetry') && !options.opentelemetry) {
      throw new Error('OpenTelemetry configuration is required when OpenTelemetry feature is enabled');
    }
  }

  private ensureDirectoryExists(dir: string): void {
    if (!existsSync(dir)) {
      mkdirSync(dir, { recursive: true });
    }
  }

  private async generatePrometheusConfig(options: MonitoringGeneratorOptions, outputDir: string): Promise<void> {
    const prometheusDir = join(outputDir, 'prometheus');
    this.ensureDirectoryExists(prometheusDir);

    // Generate prometheus.yml
    const prometheusConfig = {
      global: {
        scrape_interval: options.prometheus.scrapeInterval,
        evaluation_interval: options.prometheus.evaluationInterval,
        external_labels: {
          environment: options.environment,
          project: options.projectName
        }
      },
      rule_files: [
        'rules/*.yml'
      ],
      alerting: {
        alertmanagers: [
          {
            static_configs: [
              {
                targets: ['alertmanager:9093']
              }
            ]
          }
        ]
      },
      scrape_configs: [
        ...this.generateScrapeConfigs(options),
        ...options.prometheus.serviceDiscovery.staticConfigs.map(config => ({
          job_name: config.jobName,
          static_configs: [
            {
              targets: config.targets,
              labels: config.labels
            }
          ],
          metrics_path: config.metricsPath || '/metrics',
          scrape_interval: config.scrapeInterval || options.prometheus.scrapeInterval
        }))
      ],
      remote_write: options.prometheus.enableRemoteWrite && options.prometheus.remoteWriteConfig ? [
        {
          url: options.prometheus.remoteWriteConfig.url,
          headers: options.prometheus.remoteWriteConfig.headers,
          basic_auth: options.prometheus.remoteWriteConfig.basicAuth
        }
      ] : undefined
    };

    writeFileSync(
      join(prometheusDir, 'prometheus.yml'),
      this.yamlStringify(prometheusConfig)
    );

    // Generate alerting rules
    await this.generateAlertingRules(options, prometheusDir);
    
    // Generate recording rules
    await this.generateRecordingRules(options, prometheusDir);

    this.logger.info('Generated Prometheus 3.0 configuration');
  }

  private generateScrapeConfigs(options: MonitoringGeneratorOptions): any[] {
    const configs = [];

    // Application metrics
    configs.push({
      job_name: options.projectName,
      static_configs: [
        {
          targets: ['localhost:3000']
        }
      ],
      metrics_path: '/metrics',
      scrape_interval: '15s'
    });

    // Node exporter
    if (options.features.includes('node-exporter')) {
      configs.push({
        job_name: 'node-exporter',
        static_configs: [
          {
            targets: ['node-exporter:9100']
          }
        ]
      });
    }

    // cAdvisor
    if (options.features.includes('cadvisor')) {
      configs.push({
        job_name: 'cadvisor',
        static_configs: [
          {
            targets: ['cadvisor:8080']
          }
        ]
      });
    }

    // Blackbox exporter
    if (options.features.includes('blackbox-exporter')) {
      configs.push({
        job_name: 'blackbox',
        metrics_path: '/probe',
        params: {
          module: ['http_2xx']
        },
        static_configs: [
          {
            targets: ['http://localhost:3000/health']
          }
        ],
        relabel_configs: [
          {
            source_labels: ['__address__'],
            target_label: '__param_target'
          },
          {
            source_labels: ['__param_target'],
            target_label: 'instance'
          },
          {
            target_label: '__address__',
            replacement: 'blackbox-exporter:9115'
          }
        ]
      });
    }

    // Kubernetes service discovery
    if (options.prometheus.serviceDiscovery.kubernetes) {
      configs.push({
        job_name: 'kubernetes-apiservers',
        kubernetes_sd_configs: [
          {
            role: 'endpoints'
          }
        ],
        scheme: 'https',
        tls_config: {
          ca_file: '/var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
        },
        bearer_token_file: '/var/run/secrets/kubernetes.io/serviceaccount/token',
        relabel_configs: [
          {
            source_labels: ['__meta_kubernetes_namespace', '__meta_kubernetes_service_name', '__meta_kubernetes_endpoint_port_name'],
            action: 'keep',
            regex: 'default;kubernetes;https'
          }
        ]
      });

      configs.push({
        job_name: 'kubernetes-nodes',
        kubernetes_sd_configs: [
          {
            role: 'node'
          }
        ],
        scheme: 'https',
        tls_config: {
          ca_file: '/var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
        },
        bearer_token_file: '/var/run/secrets/kubernetes.io/serviceaccount/token',
        relabel_configs: [
          {
            action: 'labelmap',
            regex: '__meta_kubernetes_node_label_(.+)'
          }
        ]
      });

      configs.push({
        job_name: 'kubernetes-pods',
        kubernetes_sd_configs: [
          {
            role: 'pod'
          }
        ],
        relabel_configs: [
          {
            source_labels: ['__meta_kubernetes_pod_annotation_prometheus_io_scrape'],
            action: 'keep',
            regex: 'true'
          },
          {
            source_labels: ['__meta_kubernetes_pod_annotation_prometheus_io_path'],
            action: 'replace',
            target_label: '__metrics_path__',
            regex: '(.+)'
          },
          {
            source_labels: ['__address__', '__meta_kubernetes_pod_annotation_prometheus_io_port'],
            action: 'replace',
            regex: '([^:]+)(?::\\d+)?;(\\d+)',
            replacement: '${1}:${2}',
            target_label: '__address__'
          },
          {
            action: 'labelmap',
            regex: '__meta_kubernetes_pod_label_(.+)'
          },
          {
            source_labels: ['__meta_kubernetes_namespace'],
            action: 'replace',
            target_label: 'kubernetes_namespace'
          },
          {
            source_labels: ['__meta_kubernetes_pod_name'],
            action: 'replace',
            target_label: 'kubernetes_pod_name'
          }
        ]
      });
    }

    return configs;
  }

  private async generateAlertingRules(options: MonitoringGeneratorOptions, prometheusDir: string): Promise<void> {
    const rulesDir = join(prometheusDir, 'rules');
    this.ensureDirectoryExists(rulesDir);

    const defaultRules: AlertRule[] = [
      {
        name: 'InstanceDown',
        expr: 'up == 0',
        for: '5m',
        severity: 'critical',
        summary: 'Instance {{ $labels.instance }} down',
        description: 'Instance {{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.',
        annotations: {
          runbook_url: 'https://runbooks.example.com/InstanceDown'
        }
      },
      {
        name: 'HighErrorRate',
        expr: `rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.1`,
        for: '10m',
        severity: 'warning',
        summary: 'High error rate on {{ $labels.instance }}',
        description: 'Error rate is {{ $value | humanizePercentage }} on {{ $labels.instance }}.'
      },
      {
        name: 'HighLatency',
        expr: 'histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.5',
        for: '10m',
        severity: 'warning',
        summary: 'High latency on {{ $labels.instance }}',
        description: '95th percentile latency is {{ $value }}s on {{ $labels.instance }}.'
      },
      {
        name: 'DiskSpaceLow',
        expr: 'node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"} < 0.1',
        for: '5m',
        severity: 'warning',
        summary: 'Disk space low on {{ $labels.instance }}',
        description: 'Disk space is below 10% on {{ $labels.instance }}.'
      },
      {
        name: 'MemoryUsageHigh',
        expr: '(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes > 0.9',
        for: '10m',
        severity: 'warning',
        summary: 'High memory usage on {{ $labels.instance }}',
        description: 'Memory usage is above 90% on {{ $labels.instance }}.'
      },
      {
        name: 'CPUUsageHigh',
        expr: '100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 90',
        for: '10m',
        severity: 'warning',
        summary: 'High CPU usage on {{ $labels.instance }}',
        description: 'CPU usage is above 90% on {{ $labels.instance }}.'
      }
    ];

    const allRules = [...defaultRules, ...options.prometheus.alertingRules];

    const ruleGroups = {
      groups: [
        {
          name: 'application.rules',
          rules: allRules.map(rule => ({
            alert: rule.name,
            expr: rule.expr,
            for: rule.for,
            labels: {
              severity: rule.severity,
              ...rule.labels
            },
            annotations: {
              summary: rule.summary,
              description: rule.description,
              ...rule.annotations
            }
          }))
        }
      ]
    };

    writeFileSync(
      join(rulesDir, 'application.yml'),
      this.yamlStringify(ruleGroups)
    );

    this.logger.info('Generated Prometheus alerting rules');
  }

  private async generateRecordingRules(options: MonitoringGeneratorOptions, prometheusDir: string): Promise<void> {
    const rulesDir = join(prometheusDir, 'rules');
    this.ensureDirectoryExists(rulesDir);

    const defaultRecordingRules: RecordingRule[] = [
      {
        record: 'instance:node_cpu_utilisation:rate5m',
        expr: '1 - avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m]))'
      },
      {
        record: 'instance:node_load1_per_cpu:ratio',
        expr: 'node_load1 / count by (instance) (node_cpu_seconds_total{mode="idle"})'
      },
      {
        record: 'instance:node_memory_utilisation:ratio',
        expr: '1 - ((node_memory_MemAvailable_bytes or (node_memory_Buffers_bytes + node_memory_Cached_bytes + node_memory_MemFree_bytes)) / node_memory_MemTotal_bytes)'
      },
      {
        record: 'instance:node_vmstat_pgmajfault:rate5m',
        expr: 'rate(node_vmstat_pgmajfault[5m])'
      },
      {
        record: 'instance:node_disk_io_time_seconds:rate5m',
        expr: 'rate(node_disk_io_time_seconds_total[5m])'
      },
      {
        record: 'instance:node_network_receive_bytes_excluding_lo:rate5m',
        expr: 'sum by (instance) (rate(node_network_receive_bytes_total{device!="lo"}[5m]))'
      },
      {
        record: 'instance:node_network_transmit_bytes_excluding_lo:rate5m',
        expr: 'sum by (instance) (rate(node_network_transmit_bytes_total{device!="lo"}[5m]))'
      },
      {
        record: 'job:http_requests:rate5m',
        expr: 'sum by (job) (rate(http_requests_total[5m]))'
      },
      {
        record: 'job:http_request_duration_seconds:p95',
        expr: 'histogram_quantile(0.95, sum by (job, le) (rate(http_request_duration_seconds_bucket[5m])))'
      },
      {
        record: 'job:http_request_duration_seconds:p99',
        expr: 'histogram_quantile(0.99, sum by (job, le) (rate(http_request_duration_seconds_bucket[5m])))'
      }
    ];

    const allRecordingRules = [...defaultRecordingRules, ...options.prometheus.recordingRules];

    const recordingRuleGroups = {
      groups: [
        {
          name: 'recording.rules',
          interval: '30s',
          rules: allRecordingRules.map(rule => ({
            record: rule.record,
            expr: rule.expr,
            labels: rule.labels
          }))
        }
      ]
    };

    writeFileSync(
      join(rulesDir, 'recording.yml'),
      this.yamlStringify(recordingRuleGroups)
    );

    this.logger.info('Generated Prometheus recording rules');
  }

  private async generateGrafanaConfig(options: MonitoringGeneratorOptions, outputDir: string): Promise<void> {
    const grafanaDir = join(outputDir, 'grafana');
    this.ensureDirectoryExists(grafanaDir);

    // Generate datasources
    await this.generateGrafanaDatasources(options, grafanaDir);
    
    // Generate dashboards
    await this.generateGrafanaDashboards(options, grafanaDir);
    
    // Generate provisioning configuration
    await this.generateGrafanaProvisioning(options, grafanaDir);

    this.logger.info('Generated Grafana configuration');
  }

  private async generateGrafanaDatasources(options: MonitoringGeneratorOptions, grafanaDir: string): Promise<void> {
    const provisioningDir = join(grafanaDir, 'provisioning', 'datasources');
    this.ensureDirectoryExists(provisioningDir);

    const datasources = {
      apiVersion: 1,
      datasources: options.grafana.datasources.map(ds => ({
        name: ds.name,
        type: ds.type,
        access: ds.access,
        url: ds.url,
        isDefault: ds.isDefault,
        basicAuth: ds.basicAuth || false,
        jsonData: ds.jsonData || {},
        editable: true
      }))
    };

    writeFileSync(
      join(provisioningDir, 'datasources.yml'),
      this.yamlStringify(datasources)
    );
  }

  private async generateGrafanaDashboards(options: MonitoringGeneratorOptions, grafanaDir: string): Promise<void> {
    const dashboardsDir = join(grafanaDir, 'dashboards');
    this.ensureDirectoryExists(dashboardsDir);

    // Generate application dashboard
    const appDashboard = this.generateApplicationDashboard(options);
    writeFileSync(
      join(dashboardsDir, 'application.json'),
      JSON.stringify(appDashboard, null, 2)
    );

    // Generate infrastructure dashboard
    const infraDashboard = this.generateInfrastructureDashboard(options);
    writeFileSync(
      join(dashboardsDir, 'infrastructure.json'),
      JSON.stringify(infraDashboard, null, 2)
    );

    // Generate custom dashboards
    for (const dashboard of options.grafana.dashboards) {
      writeFileSync(
        join(dashboardsDir, `${dashboard.name.toLowerCase().replace(/\s+/g, '-')}.json`),
        JSON.stringify(dashboard, null, 2)
      );
    }
  }

  private generateApplicationDashboard(options: MonitoringGeneratorOptions): any {
    return {
      dashboard: {
        id: null,
        uid: 'app-overview',
        title: `${options.projectName} - Application Overview`,
        tags: ['application', options.projectName],
        timezone: 'browser',
        panels: [
          {
            id: 1,
            title: 'Request Rate',
            type: 'graph',
            targets: [
              {
                expr: `rate(http_requests_total{job="${options.projectName}"}[5m])`,
                legendFormat: '{{method}} {{status}}',
                refId: 'A'
              }
            ],
            gridPos: { h: 8, w: 12, x: 0, y: 0 },
            yAxes: [
              {
                label: 'requests/sec',
                show: true
              }
            ]
          },
          {
            id: 2,
            title: 'Response Time (95th percentile)',
            type: 'graph',
            targets: [
              {
                expr: `histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="${options.projectName}"}[5m]))`,
                legendFormat: 'p95',
                refId: 'A'
              }
            ],
            gridPos: { h: 8, w: 12, x: 12, y: 0 },
            yAxes: [
              {
                label: 'seconds',
                show: true
              }
            ]
          },
          {
            id: 3,
            title: 'Error Rate',
            type: 'stat',
            targets: [
              {
                expr: `rate(http_requests_total{job="${options.projectName}",status=~"5.."}[5m]) / rate(http_requests_total{job="${options.projectName}"}[5m])`,
                refId: 'A'
              }
            ],
            gridPos: { h: 4, w: 6, x: 0, y: 8 },
            fieldConfig: {
              defaults: {
                unit: 'percentunit',
                thresholds: {
                  steps: [
                    { color: 'green', value: null },
                    { color: 'yellow', value: 0.01 },
                    { color: 'red', value: 0.05 }
                  ]
                }
              }
            }
          },
          {
            id: 4,
            title: 'Active Connections',
            type: 'stat',
            targets: [
              {
                expr: `nodejs_active_handles{job="${options.projectName}"}`,
                refId: 'A'
              }
            ],
            gridPos: { h: 4, w: 6, x: 6, y: 8 }
          },
          {
            id: 5,
            title: 'Memory Usage',
            type: 'graph',
            targets: [
              {
                expr: `process_resident_memory_bytes{job="${options.projectName}"}`,
                legendFormat: 'RSS',
                refId: 'A'
              },
              {
                expr: `nodejs_heap_size_used_bytes{job="${options.projectName}"}`,
                legendFormat: 'Heap Used',
                refId: 'B'
              }
            ],
            gridPos: { h: 8, w: 12, x: 12, y: 8 },
            yAxes: [
              {
                label: 'bytes',
                show: true
              }
            ]
          }
        ],
        time: {
          from: 'now-1h',
          to: 'now'
        },
        refresh: '30s'
      }
    };
  }

  private generateInfrastructureDashboard(options: MonitoringGeneratorOptions): any {
    return {
      dashboard: {
        id: null,
        uid: 'infrastructure-overview',
        title: 'Infrastructure Overview',
        tags: ['infrastructure', 'monitoring'],
        timezone: 'browser',
        panels: [
          {
            id: 1,
            title: 'CPU Usage',
            type: 'graph',
            targets: [
              {
                expr: '100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)',
                legendFormat: '{{instance}}',
                refId: 'A'
              }
            ],
            gridPos: { h: 8, w: 12, x: 0, y: 0 },
            yAxes: [
              {
                label: 'percent',
                max: 100,
                min: 0,
                show: true
              }
            ]
          },
          {
            id: 2,
            title: 'Memory Usage',
            type: 'graph',
            targets: [
              {
                expr: '(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100',
                legendFormat: '{{instance}}',
                refId: 'A'
              }
            ],
            gridPos: { h: 8, w: 12, x: 12, y: 0 },
            yAxes: [
              {
                label: 'percent',
                max: 100,
                min: 0,
                show: true
              }
            ]
          },
          {
            id: 3,
            title: 'Disk Usage',
            type: 'graph',
            targets: [
              {
                expr: '(node_filesystem_size_bytes{mountpoint="/"} - node_filesystem_avail_bytes{mountpoint="/"}) / node_filesystem_size_bytes{mountpoint="/"} * 100',
                legendFormat: '{{instance}}',
                refId: 'A'
              }
            ],
            gridPos: { h: 8, w: 12, x: 0, y: 8 }
          },
          {
            id: 4,
            title: 'Network I/O',
            type: 'graph',
            targets: [
              {
                expr: 'rate(node_network_receive_bytes_total{device!="lo"}[5m])',
                legendFormat: 'RX {{instance}} {{device}}',
                refId: 'A'
              },
              {
                expr: 'rate(node_network_transmit_bytes_total{device!="lo"}[5m])',
                legendFormat: 'TX {{instance}} {{device}}',
                refId: 'B'
              }
            ],
            gridPos: { h: 8, w: 12, x: 12, y: 8 }
          }
        ],
        time: {
          from: 'now-1h',
          to: 'now'
        },
        refresh: '30s'
      }
    };
  }

  private async generateGrafanaProvisioning(options: MonitoringGeneratorOptions, grafanaDir: string): Promise<void> {
    const provisioningDir = join(grafanaDir, 'provisioning');
    
    // Dashboard provisioning
    const dashboardProvisioningDir = join(provisioningDir, 'dashboards');
    this.ensureDirectoryExists(dashboardProvisioningDir);

    const dashboardProvisioning = {
      apiVersion: 1,
      providers: [
        {
          name: 'default',
          orgId: 1,
          folder: '',
          type: 'file',
          disableDeletion: false,
          updateIntervalSeconds: 10,
          allowUiUpdates: true,
          options: {
            path: '/etc/grafana/provisioning/dashboards'
          }
        }
      ]
    };

    writeFileSync(
      join(dashboardProvisioningDir, 'dashboards.yml'),
      this.yamlStringify(dashboardProvisioning)
    );
  }

  private async generateOpenTelemetryConfig(options: MonitoringGeneratorOptions, outputDir: string): Promise<void> {
    const otelDir = join(outputDir, 'opentelemetry');
    this.ensureDirectoryExists(otelDir);

    const collectorConfig = {
      receivers: {
        otlp: {
          protocols: {
            grpc: {
              endpoint: '0.0.0.0:4317'
            },
            http: {
              endpoint: '0.0.0.0:4318'
            }
          }
        },
        prometheus: {
          config: {
            scrape_configs: [
              {
                job_name: 'otel-collector',
                scrape_interval: '10s',
                static_configs: [
                  {
                    targets: ['0.0.0.0:8888']
                  }
                ]
              }
            ]
          }
        }
      },
      processors: {
        batch: {},
        memory_limiter: {
          limit_mib: 512
        },
        resource: {
          attributes: [
            {
              key: 'service.name',
              value: options.projectName,
              action: 'upsert'
            },
            {
              key: 'service.version',
              value: '1.0.0',
              action: 'upsert'
            },
            {
              key: 'deployment.environment',
              value: options.environment,
              action: 'upsert'
            }
          ]
        }
      },
      exporters: {
        prometheus: {
          endpoint: '0.0.0.0:8889'
        },
        logging: {
          loglevel: 'debug'
        }
      },
      extensions: {
        health_check: {},
        pprof: {
          endpoint: '0.0.0.0:1777'
        },
        zpages: {
          endpoint: '0.0.0.0:55679'
        }
      },
      service: {
        extensions: ['health_check', 'pprof', 'zpages'],
        pipelines: {
          traces: {
            receivers: ['otlp'],
            processors: ['memory_limiter', 'resource', 'batch'],
            exporters: ['logging']
          },
          metrics: {
            receivers: ['otlp', 'prometheus'],
            processors: ['memory_limiter', 'resource', 'batch'],
            exporters: ['prometheus', 'logging']
          },
          logs: {
            receivers: ['otlp'],
            processors: ['memory_limiter', 'resource', 'batch'],
            exporters: ['logging']
          }
        }
      }
    };

    // Add Jaeger exporter if enabled
    if (options.features.includes('jaeger')) {
      collectorConfig.exporters['jaeger'] = {
        endpoint: 'jaeger:14250',
        tls: {
          insecure: true
        }
      };
      collectorConfig.service.pipelines.traces.exporters.push('jaeger');
    }

    // Add Tempo exporter if enabled
    if (options.features.includes('tempo')) {
      collectorConfig.exporters['otlp/tempo'] = {
        endpoint: 'tempo:4317',
        tls: {
          insecure: true
        }
      };
      collectorConfig.service.pipelines.traces.exporters.push('otlp/tempo');
    }

    // Add Loki exporter if enabled
    if (options.features.includes('loki')) {
      collectorConfig.exporters['loki'] = {
        endpoint: 'http://loki:3100/loki/api/v1/push'
      };
      collectorConfig.service.pipelines.logs.exporters.push('loki');
    }

    writeFileSync(
      join(otelDir, 'collector-config.yml'),
      this.yamlStringify(collectorConfig)
    );

    this.logger.info('Generated OpenTelemetry Collector configuration');
  }

  private async generateLokiConfig(options: MonitoringGeneratorOptions, outputDir: string): Promise<void> {
    const lokiDir = join(outputDir, 'loki');
    this.ensureDirectoryExists(lokiDir);

    const lokiConfig = {
      auth_enabled: false,
      server: {
        http_listen_port: 3100,
        grpc_listen_port: 9096
      },
      common: {
        path_prefix: '/tmp/loki',
        storage: {
          filesystem: {
            chunks_directory: '/tmp/loki/chunks',
            rules_directory: '/tmp/loki/rules'
          }
        },
        replication_factor: 1,
        ring: {
          instance_addr: '127.0.0.1',
          kvstore: {
            store: 'inmemory'
          }
        }
      },
      schema_config: {
        configs: [
          {
            from: '2020-10-24',
            store: 'boltdb-shipper',
            object_store: 'filesystem',
            schema: 'v11',
            index: {
              prefix: 'index_',
              period: '24h'
            }
          }
        ]
      },
      analytics: {
        reporting_enabled: false
      }
    };

    writeFileSync(
      join(lokiDir, 'loki-config.yml'),
      this.yamlStringify(lokiConfig)
    );

    this.logger.info('Generated Loki configuration');
  }

  private async generateTempoConfig(options: MonitoringGeneratorOptions, outputDir: string): Promise<void> {
    const tempoDir = join(outputDir, 'tempo');
    this.ensureDirectoryExists(tempoDir);

    const tempoConfig = {
      server: {
        http_listen_port: 3200
      },
      distributor: {
        receivers: {
          jaeger: {
            protocols: {
              thrift_http: {
                endpoint: '0.0.0.0:14268'
              },
              grpc: {
                endpoint: '0.0.0.0:14250'
              }
            }
          },
          zipkin: {
            endpoint: '0.0.0.0:9411'
          },
          otlp: {
            protocols: {
              http: {
                endpoint: '0.0.0.0:4318'
              },
              grpc: {
                endpoint: '0.0.0.0:4317'
              }
            }
          }
        }
      },
      ingester: {
        trace_idle_period: '10s',
        max_block_bytes: 1_000_000,
        max_block_duration: '5m'
      },
      compactor: {
        compaction: {
          compacted_block_retention: '1h'
        }
      },
      storage: {
        trace: {
          backend: 'local',
          local: {
            path: '/tmp/tempo/traces'
          }
        }
      }
    };

    writeFileSync(
      join(tempoDir, 'tempo-config.yml'),
      this.yamlStringify(tempoConfig)
    );

    this.logger.info('Generated Tempo configuration');
  }

  private async generateJaegerConfig(options: MonitoringGeneratorOptions, outputDir: string): Promise<void> {
    const jaegerDir = join(outputDir, 'jaeger');
    this.ensureDirectoryExists(jaegerDir);

    // Jaeger is typically configured via environment variables
    const jaegerEnv = {
      COLLECTOR_OTLP_ENABLED: 'true',
      SPAN_STORAGE_TYPE: 'memory',
      JAEGER_DISABLED: 'false',
      JAEGER_SERVICE_NAME: options.projectName,
      JAEGER_AGENT_HOST: 'jaeger',
      JAEGER_AGENT_PORT: '6831',
      JAEGER_SAMPLER_TYPE: 'const',
      JAEGER_SAMPLER_PARAM: '1'
    };

    writeFileSync(
      join(jaegerDir, 'jaeger.env'),
      Object.entries(jaegerEnv)
        .map(([key, value]) => `${key}=${value}`)
        .join('\n')
    );

    this.logger.info('Generated Jaeger configuration');
  }

  private async generateAlertmanagerConfig(options: MonitoringGeneratorOptions, outputDir: string): Promise<void> {
    const alertmanagerDir = join(outputDir, 'alertmanager');
    this.ensureDirectoryExists(alertmanagerDir);

    const alertmanagerConfig = {
      global: {
        smtp_smarthost: 'localhost:587',
        smtp_from: 'alertmanager@example.com',
        resolve_timeout: '5m'
      },
      route: options.alerting.alertmanager.route,
      receivers: options.alerting.alertmanager.receivers,
      inhibit_rules: options.alerting.alertmanager.inhibitRules || []
    };

    writeFileSync(
      join(alertmanagerDir, 'alertmanager.yml'),
      this.yamlStringify(alertmanagerConfig)
    );

    this.logger.info('Generated Alertmanager configuration');
  }

  private async generateNodeExporterConfig(options: MonitoringGeneratorOptions, outputDir: string): Promise<void> {
    const nodeExporterDir = join(outputDir, 'node-exporter');
    this.ensureDirectoryExists(nodeExporterDir);

    // Node Exporter configuration (if needed)
    const nodeExporterConfig = {
      collectors: {
        enabled: [
          'cpu',
          'diskstats',
          'filesystem',
          'loadavg',
          'meminfo',
          'netdev',
          'netstat',
          'stat',
          'time',
          'uname',
          'vmstat'
        ]
      }
    };

    writeFileSync(
      join(nodeExporterDir, 'node-exporter-config.yml'),
      this.yamlStringify(nodeExporterConfig)
    );

    this.logger.info('Generated Node Exporter configuration');
  }

  private async generateBlackboxExporterConfig(options: MonitoringGeneratorOptions, outputDir: string): Promise<void> {
    const blackboxDir = join(outputDir, 'blackbox-exporter');
    this.ensureDirectoryExists(blackboxDir);

    const blackboxConfig = {
      modules: {
        http_2xx: {
          prober: 'http',
          timeout: '5s',
          http: {
            valid_http_versions: ['HTTP/1.1', 'HTTP/2.0'],
            valid_status_codes: [],
            method: 'GET',
            headers: {
              'Host': 'example.com',
              'Accept-Language': 'en-US'
            },
            no_follow_redirects: false,
            fail_if_ssl: false,
            fail_if_not_ssl: false,
            tls_config: {
              insecure_skip_verify: false
            },
            preferred_ip_protocol: 'ip4'
          }
        },
        http_post_2xx: {
          prober: 'http',
          timeout: '5s',
          http: {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json'
            },
            body: '{}'
          }
        },
        tcp_connect: {
          prober: 'tcp',
          timeout: '5s'
        },
        icmp: {
          prober: 'icmp',
          timeout: '5s',
          icmp: {
            preferred_ip_protocol: 'ip4'
          }
        }
      }
    };

    writeFileSync(
      join(blackboxDir, 'blackbox-config.yml'),
      this.yamlStringify(blackboxConfig)
    );

    this.logger.info('Generated Blackbox Exporter configuration');
  }

  private async generateApplicationInstrumentation(options: MonitoringGeneratorOptions, outputDir: string): Promise<void> {
    const instrumentationDir = join(outputDir, 'instrumentation');
    this.ensureDirectoryExists(instrumentationDir);

    // Generate runtime-specific instrumentation code
    switch (options.runtime) {
      case 'node':
        await this.generateNodeInstrumentation(options, instrumentationDir);
        break;
      case 'python':
        await this.generatePythonInstrumentation(options, instrumentationDir);
        break;
      case 'go':
        await this.generateGoInstrumentation(options, instrumentationDir);
        break;
      case 'java':
        await this.generateJavaInstrumentation(options, instrumentationDir);
        break;
      case 'dotnet':
        await this.generateDotNetInstrumentation(options, instrumentationDir);
        break;
    }

    this.logger.info(`Generated ${options.runtime} instrumentation code`);
  }

  private async generateNodeInstrumentation(options: MonitoringGeneratorOptions, instrumentationDir: string): Promise<void> {
    // Prometheus metrics
    const prometheusInstrumentation = `// Prometheus metrics instrumentation for ${options.projectName}
// Generated by Xaheen CLI

import { register, Counter, Histogram, Gauge, collectDefaultMetrics } from 'prom-client';
import express from 'express';

// Collect default metrics
collectDefaultMetrics();

// Custom metrics
export const httpRequestTotal = new Counter({
  name: 'http_requests_total',
  help: 'Total number of HTTP requests',
  labelNames: ['method', 'route', 'status'],
});

export const httpRequestDuration = new Histogram({
  name: 'http_request_duration_seconds',
  help: 'Duration of HTTP requests in seconds',
  labelNames: ['method', 'route', 'status'],
  buckets: [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10],
});

export const activeConnections = new Gauge({
  name: 'active_connections',
  help: 'Number of active connections',
});

export const databaseConnectionsActive = new Gauge({
  name: 'database_connections_active',
  help: 'Number of active database connections',
});

export const databaseConnectionsIdle = new Gauge({
  name: 'database_connections_idle',
  help: 'Number of idle database connections',
});

// Middleware to collect HTTP metrics
export const metricsMiddleware = (req: express.Request, res: express.Response, next: express.NextFunction) => {
  const startTime = process.hrtime.bigint();
  
  res.on('finish', () => {
    const endTime = process.hrtime.bigint();
    const duration = Number(endTime - startTime) / 1e9; // Convert to seconds
    
    const labels = {
      method: req.method,
      route: req.route?.path || req.path,
      status: res.statusCode.toString(),
    };
    
    httpRequestTotal.inc(labels);
    httpRequestDuration.observe(labels, duration);
  });
  
  next();
};

// Health check endpoint
export const healthCheck = (req: express.Request, res: express.Response) => {
  res.status(200).json({
    status: 'healthy',
    timestamp: new Date().toISOString(),
    uptime: process.uptime(),
    memory: process.memoryUsage(),
  });
};

// Metrics endpoint
export const metricsEndpoint = async (req: express.Request, res: express.Response) => {
  try {
    res.set('Content-Type', register.contentType);
    res.end(await register.metrics());
  } catch (error) {
    res.status(500).end(error);
  }
};

// Error tracking
export const errorCounter = new Counter({
  name: 'application_errors_total',
  help: 'Total number of application errors',
  labelNames: ['type', 'severity'],
});

export const trackError = (error: Error, severity: 'low' | 'medium' | 'high' | 'critical' = 'medium') => {
  errorCounter.inc({
    type: error.constructor.name,
    severity,
  });
  
  console.error('[ERROR]', {
    message: error.message,
    stack: error.stack,
    severity,
    timestamp: new Date().toISOString(),
  });
};
`;

    writeFileSync(join(instrumentationDir, 'prometheus.ts'), prometheusInstrumentation);

    // OpenTelemetry instrumentation
    const otelInstrumentation = `// OpenTelemetry instrumentation for ${options.projectName}
// Generated by Xaheen CLI

import { NodeSDK } from '@opentelemetry/sdk-node';
import { Resource } from '@opentelemetry/resources';
import { SemanticResourceAttributes } from '@opentelemetry/semantic-conventions';
import { getNodeAutoInstrumentations } from '@opentelemetry/auto-instrumentations-node';
import { PeriodicExportingMetricReader, ConsoleMetricExporter } from '@opentelemetry/sdk-metrics';
import { PrometheusExporter } from '@opentelemetry/exporter-prometheus';
import { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-http';
import { OTLPMetricExporter } from '@opentelemetry/exporter-metrics-otlp-http';
import { BatchSpanProcessor } from '@opentelemetry/sdk-trace-node';

// Configure the SDK
const sdk = new NodeSDK({
  resource: new Resource({
    [SemanticResourceAttributes.SERVICE_NAME]: '${options.projectName}',
    [SemanticResourceAttributes.SERVICE_VERSION]: '1.0.0',
    [SemanticResourceAttributes.DEPLOYMENT_ENVIRONMENT]: '${options.environment}',
  }),
  
  // Auto-instrumentations
  instrumentations: [
    getNodeAutoInstrumentations({
      '@opentelemetry/instrumentation-http': {
        enabled: true,
        ignoreIncomingRequestHook: (req) => {
          return req.url?.includes('/metrics') || req.url?.includes('/health');
        },
      },
      '@opentelemetry/instrumentation-express': {
        enabled: true,
      },
      '@opentelemetry/instrumentation-fs': {
        enabled: false, // Can be noisy
      },
    }),
  ],
  
  // Trace exporters
  spanProcessor: new BatchSpanProcessor(
    new OTLPTraceExporter({
      url: process.env.OTEL_EXPORTER_OTLP_TRACES_ENDPOINT || 'http://otel-collector:4318/v1/traces',
    })
  ),
  
  // Metric exporters
  metricReader: new PeriodicExportingMetricReader({
    exporter: new OTLPMetricExporter({
      url: process.env.OTEL_EXPORTER_OTLP_METRICS_ENDPOINT || 'http://otel-collector:4318/v1/metrics',
    }),
    exportIntervalMillis: 30000,
  }),
});

// Initialize the SDK
sdk.start();

// Graceful shutdown
process.on('SIGTERM', () => {
  sdk.shutdown()
    .then(() => console.log('OpenTelemetry terminated'))
    .catch((error) => console.log('Error terminating OpenTelemetry', error))
    .finally(() => process.exit(0));
});

// Export SDK for custom usage
export { sdk };

// Utility functions for manual instrumentation
import { trace, metrics, SpanKind, SpanStatusCode } from '@opentelemetry/api';

const tracer = trace.getTracer('${options.projectName}');
const meter = metrics.getMeter('${options.projectName}');

// Custom counters and histograms
export const customCounter = meter.createCounter('custom_operations_total', {
  description: 'Total number of custom operations',
});

export const customHistogram = meter.createHistogram('custom_operation_duration', {
  description: 'Duration of custom operations',
});

// Manual span creation
export const createSpan = (name: string, operation: () => Promise<any> | any) => {
  const span = tracer.startSpan(name, {
    kind: SpanKind.INTERNAL,
  });
  
  return trace.setSpan(trace.active(), span).with(() => {
    try {
      const result = operation();
      
      if (result instanceof Promise) {
        return result
          .then((res) => {
            span.setStatus({ code: SpanStatusCode.OK });
            return res;
          })
          .catch((error) => {
            span.recordException(error);
            span.setStatus({ code: SpanStatusCode.ERROR, message: error.message });
            throw error;
          })
          .finally(() => {
            span.end();
          });
      } else {
        span.setStatus({ code: SpanStatusCode.OK });
        span.end();
        return result;
      }
    } catch (error) {
      span.recordException(error as Error);
      span.setStatus({ code: SpanStatusCode.ERROR, message: (error as Error).message });
      span.end();
      throw error;
    }
  });
};

// Add correlation IDs to logs
export const addCorrelationId = () => {
  const span = trace.getActiveSpan();
  if (span) {
    const spanContext = span.spanContext();
    return {
      traceId: spanContext.traceId,
      spanId: spanContext.spanId,
    };
  }
  return {};
};
`;

    writeFileSync(join(instrumentationDir, 'opentelemetry.ts'), otelInstrumentation);

    // Package.json additions
    const packageAdditions = {
      dependencies: {
        'prom-client': '^15.1.0',
        '@opentelemetry/sdk-node': '^0.45.0',
        '@opentelemetry/resources': '^1.18.0',
        '@opentelemetry/semantic-conventions': '^1.18.0',
        '@opentelemetry/auto-instrumentations-node': '^0.40.0',
        '@opentelemetry/sdk-metrics': '^1.18.0',
        '@opentelemetry/exporter-prometheus': '^0.45.0',
        '@opentelemetry/exporter-trace-otlp-http': '^0.45.0',
        '@opentelemetry/exporter-metrics-otlp-http': '^0.45.0',
        '@opentelemetry/sdk-trace-node': '^1.18.0'
      }
    };

    writeFileSync(
      join(instrumentationDir, 'package-additions.json'),
      JSON.stringify(packageAdditions, null, 2)
    );
  }

  private async generatePythonInstrumentation(options: MonitoringGeneratorOptions, instrumentationDir: string): Promise<void> {
    const prometheusInstrumentation = `# Prometheus metrics instrumentation for ${options.projectName}
# Generated by Xaheen CLI

from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST
from prometheus_client import start_http_server, CollectorRegistry, REGISTRY
import time
import functools
from flask import Flask, request, Response
import logging

# Custom metrics
http_requests_total = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

http_request_duration_seconds = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration in seconds',
    ['method', 'endpoint', 'status'],
    buckets=[0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10]
)

active_connections = Gauge(
    'active_connections',
    'Active connections'
)

database_connections_active = Gauge(
    'database_connections_active',
    'Active database connections'
)

application_errors_total = Counter(
    'application_errors_total',
    'Total application errors',
    ['type', 'severity']
)

def metrics_middleware(app: Flask):
    """Flask middleware to collect HTTP metrics"""
    
    @app.before_request
    def before_request():
        request.start_time = time.time()
        active_connections.inc()
    
    @app.after_request
    def after_request(response):
        request_latency = time.time() - request.start_time
        
        labels = {
            'method': request.method,
            'endpoint': request.endpoint or request.path,
            'status': str(response.status_code)
        }
        
        http_requests_total.labels(**labels).inc()
        http_request_duration_seconds.labels(**labels).observe(request_latency)
        active_connections.dec()
        
        return response
    
    return app

def track_error(error: Exception, severity: str = 'medium'):
    """Track application errors"""
    application_errors_total.labels(
        type=type(error).__name__,
        severity=severity
    ).inc()
    
    logging.error(f"Application error: {error}", extra={
        'error_type': type(error).__name__,
        'severity': severity,
        'timestamp': time.time()
    })

def metrics_endpoint():
    """Metrics endpoint for Prometheus scraping"""
    return Response(generate_latest(REGISTRY), mimetype=CONTENT_TYPE_LATEST)

def health_check():
    """Health check endpoint"""
    import psutil
    import os
    
    return {
        'status': 'healthy',
        'timestamp': time.time(),
        'uptime': time.time() - psutil.Process(os.getpid()).create_time(),
        'memory': psutil.virtual_memory()._asdict(),
        'cpu_percent': psutil.cpu_percent()
    }

# Decorator for timing functions
def time_function(metric_name: str = None):
    def decorator(func):
        nonlocal metric_name
        if metric_name is None:
            metric_name = f"{func.__module__}_{func.__name__}_duration_seconds"
        
        histogram = Histogram(metric_name, f"Duration of {func.__name__}")
        
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            with histogram.time():
                return func(*args, **kwargs)
        return wrapper
    return decorator
`;

    writeFileSync(join(instrumentationDir, 'prometheus_metrics.py'), prometheusInstrumentation);

    const otelInstrumentation = `# OpenTelemetry instrumentation for ${options.projectName}
# Generated by Xaheen CLI

from opentelemetry import trace, metrics
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.sdk.metrics import MeterProvider
from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader
from opentelemetry.sdk.resources import Resource
from opentelemetry.semconv.resource import ResourceAttributes
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.exporter.otlp.proto.http.metric_exporter import OTLPMetricExporter
from opentelemetry.instrumentation.flask import FlaskInstrumentor
from opentelemetry.instrumentation.requests import RequestsInstrumentor
from opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor
import os
import logging

# Configure resource
resource = Resource.create({
    ResourceAttributes.SERVICE_NAME: "${options.projectName}",
    ResourceAttributes.SERVICE_VERSION: "1.0.0",
    ResourceAttributes.DEPLOYMENT_ENVIRONMENT: "${options.environment}",
})

# Configure tracing
trace.set_tracer_provider(TracerProvider(resource=resource))
tracer_provider = trace.get_tracer_provider()

# Configure trace exporter
otlp_trace_exporter = OTLPSpanExporter(
    endpoint=os.getenv('OTEL_EXPORTER_OTLP_TRACES_ENDPOINT', 'http://otel-collector:4318/v1/traces')
)
span_processor = BatchSpanProcessor(otlp_trace_exporter)
tracer_provider.add_span_processor(span_processor)

# Configure metrics
metric_reader = PeriodicExportingMetricReader(
    exporter=OTLPMetricExporter(
        endpoint=os.getenv('OTEL_EXPORTER_OTLP_METRICS_ENDPOINT', 'http://otel-collector:4318/v1/metrics')
    ),
    export_interval_millis=30000,
)
metrics.set_meter_provider(MeterProvider(resource=resource, metric_readers=[metric_reader]))

# Get tracer and meter
tracer = trace.get_tracer(__name__)
meter = metrics.get_meter(__name__)

# Custom metrics
custom_counter = meter.create_counter(
    "custom_operations_total",
    description="Total number of custom operations"
)

custom_histogram = meter.create_histogram(
    "custom_operation_duration",
    description="Duration of custom operations"
)

# Auto-instrumentation
def setup_auto_instrumentation(app=None):
    """Setup automatic instrumentation"""
    
    # Flask instrumentation
    if app:
        FlaskInstrumentor().instrument_app(app)
    else:
        FlaskInstrumentor().instrument()
    
    # Requests instrumentation
    RequestsInstrumentor().instrument()
    
    # SQLAlchemy instrumentation (if using SQLAlchemy)
    try:
        SQLAlchemyInstrumentor().instrument()
    except Exception as e:
        logging.warning(f"SQLAlchemy instrumentation failed: {e}")

# Manual instrumentation helpers
def create_span(name: str, kind=trace.SpanKind.INTERNAL):
    """Create a new span"""
    return tracer.start_span(name, kind=kind)

def add_correlation_id():
    """Add correlation ID from current span"""
    span = trace.get_current_span()
    if span and span.is_recording():
        span_context = span.get_span_context()
        return {
            'trace_id': format(span_context.trace_id, '032x'),
            'span_id': format(span_context.span_id, '016x'),
        }
    return {}

# Decorator for custom spans
def traced(operation_name: str = None):
    def decorator(func):
        import functools
        
        nonlocal operation_name
        if operation_name is None:
            operation_name = f"{func.__module__}.{func.__name__}"
        
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            with tracer.start_as_current_span(operation_name) as span:
                try:
                    result = func(*args, **kwargs)
                    span.set_status(trace.Status(trace.StatusCode.OK))
                    return result
                except Exception as e:
                    span.record_exception(e)
                    span.set_status(trace.Status(trace.StatusCode.ERROR, str(e)))
                    raise
        return wrapper
    return decorator

# Logging configuration with correlation
class CorrelationFormatter(logging.Formatter):
    def format(self, record):
        correlation = add_correlation_id()
        record.trace_id = correlation.get('trace_id', 'N/A')
        record.span_id = correlation.get('span_id', 'N/A')
        return super().format(record)

def setup_logging():
    """Setup logging with correlation IDs"""
    formatter = CorrelationFormatter(
        '%(asctime)s - %(name)s - %(levelname)s - [trace_id=%(trace_id)s span_id=%(span_id)s] - %(message)s'
    )
    
    handler = logging.StreamHandler()
    handler.setFormatter(formatter)
    
    logger = logging.getLogger()
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)
    
    return logger
`;

    writeFileSync(join(instrumentationDir, 'opentelemetry_setup.py'), otelInstrumentation);

    // Requirements additions
    const requirements = `# Additional requirements for monitoring
# Generated by Xaheen CLI

prometheus-client==0.19.0
opentelemetry-api==1.21.0
opentelemetry-sdk==1.21.0
opentelemetry-instrumentation==0.42b0
opentelemetry-instrumentation-flask==0.42b0
opentelemetry-instrumentation-requests==0.42b0
opentelemetry-instrumentation-sqlalchemy==0.42b0
opentelemetry-exporter-otlp-proto-http==1.21.0
psutil==5.9.6
`;

    writeFileSync(join(instrumentationDir, 'requirements-monitoring.txt'), requirements);
  }

  private async generateGoInstrumentation(_options: MonitoringGeneratorOptions, _instrumentationDir: string): Promise<void> {
    // Go instrumentation would go here
    // Implementation omitted for brevity
  }

  private async generateJavaInstrumentation(_options: MonitoringGeneratorOptions, _instrumentationDir: string): Promise<void> {
    // Java instrumentation would go here  
    // Implementation omitted for brevity
  }

  private async generateDotNetInstrumentation(_options: MonitoringGeneratorOptions, _instrumentationDir: string): Promise<void> {
    // .NET instrumentation would go here
    // Implementation omitted for brevity
  }

  private async generateDockerCompose(options: MonitoringGeneratorOptions, outputDir: string): Promise<void> {
    const services: Record<string, any> = {};

    // Prometheus
    if (options.features.includes('prometheus')) {
      services.prometheus = {
        image: `prom/prometheus:v${options.prometheus.version}`,
        container_name: 'prometheus',
        ports: ['9090:9090'],
        volumes: [
          './prometheus/prometheus.yml:/etc/prometheus/prometheus.yml',
          './prometheus/rules:/etc/prometheus/rules',
          'prometheus_data:/prometheus'
        ],
        command: [
          '--config.file=/etc/prometheus/prometheus.yml',
          '--storage.tsdb.path=/prometheus',
          '--web.console.libraries=/etc/prometheus/console_libraries',
          '--web.console.templates=/etc/prometheus/consoles',
          '--storage.tsdb.retention.time=' + options.prometheus.retentionTime,
          '--web.enable-lifecycle'
        ],
        restart: 'unless-stopped'
      };
    }

    // Grafana
    if (options.features.includes('grafana')) {
      services.grafana = {
        image: `grafana/grafana:${options.grafana.version}`,
        container_name: 'grafana',
        ports: ['3001:3000'],
        environment: {
          GF_SECURITY_ADMIN_PASSWORD: options.grafana.adminPassword,
          GF_USERS_ALLOW_SIGN_UP: 'false',
          GF_INSTALL_PLUGINS: options.grafana.plugins.join(',')
        },
        volumes: [
          'grafana_data:/var/lib/grafana',
          './grafana/provisioning:/etc/grafana/provisioning',
          './grafana/dashboards:/etc/grafana/provisioning/dashboards'
        ],
        restart: 'unless-stopped'
      };
    }

    // OpenTelemetry Collector
    if (options.features.includes('otel-collector')) {
      services['otel-collector'] = {
        image: `otel/opentelemetry-collector-contrib:${options.opentelemetry.version}`,
        container_name: 'otel-collector',
        ports: [
          '4317:4317', // OTLP gRPC receiver
          '4318:4318', // OTLP HTTP receiver
          '8888:8888', // Prometheus metrics
          '8889:8889', // Prometheus exporter
          '13133:13133', // Health check
          '1777:1777', // pprof
          '55679:55679' // zpages
        ],
        volumes: ['./opentelemetry/collector-config.yml:/etc/otel-collector-config.yml'],
        command: ['--config=/etc/otel-collector-config.yml'],
        restart: 'unless-stopped'
      };
    }

    // Jaeger
    if (options.features.includes('jaeger')) {
      services.jaeger = {
        image: 'jaegertracing/all-in-one:1.50',
        container_name: 'jaeger',
        ports: [
          '16686:16686', // Jaeger UI
          '14268:14268', // Jaeger collector HTTP
          '14250:14250', // Jaeger collector gRPC
          '6831:6831/udp', // Jaeger agent UDP
          '6832:6832/udp', // Jaeger agent UDP
          '5778:5778', // Jaeger agent HTTP
          '5775:5775/udp' // Jaeger agent UDP
        ],
        environment: {
          COLLECTOR_OTLP_ENABLED: 'true'
        },
        restart: 'unless-stopped'
      };
    }

    // Tempo
    if (options.features.includes('tempo')) {
      services.tempo = {
        image: 'grafana/tempo:latest',
        container_name: 'tempo',
        ports: [
          '3200:3200', // Tempo
          '4317:4317', // OTLP gRPC
          '4318:4318', // OTLP HTTP
          '9411:9411', // Zipkin
          '14268:14268' // Jaeger HTTP
        ],
        volumes: [
          './tempo/tempo-config.yml:/etc/tempo.yml',
          'tempo_data:/tmp/tempo'
        ],
        command: ['-config.file=/etc/tempo.yml'],
        restart: 'unless-stopped'
      };
    }

    // Loki
    if (options.features.includes('loki')) {
      services.loki = {
        image: 'grafana/loki:latest',
        container_name: 'loki',
        ports: ['3100:3100'],
        volumes: [
          './loki/loki-config.yml:/etc/loki/local-config.yaml',
          'loki_data:/tmp/loki'
        ],
        command: ['-config.file=/etc/loki/local-config.yaml'],
        restart: 'unless-stopped'
      };

      services.promtail = {
        image: 'grafana/promtail:latest',
        container_name: 'promtail',
        volumes: [
          '/var/log:/var/log:ro',
          '/var/lib/docker/containers:/var/lib/docker/containers:ro',
          './loki/promtail-config.yml:/etc/promtail/config.yml'
        ],
        command: ['-config.file=/etc/promtail/config.yml'],
        restart: 'unless-stopped'
      };
    }

    // Alertmanager
    if (options.features.includes('alertmanager')) {
      services.alertmanager = {
        image: `prom/alertmanager:v${options.alerting.alertmanager.version}`,
        container_name: 'alertmanager',
        ports: ['9093:9093'],
        volumes: ['./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml'],
        command: [
          '--config.file=/etc/alertmanager/alertmanager.yml',
          '--storage.path=/alertmanager',
          '--web.external-url=http://localhost:9093'
        ],
        restart: 'unless-stopped'
      };
    }

    // Node Exporter
    if (options.features.includes('node-exporter')) {
      services['node-exporter'] = {
        image: 'prom/node-exporter:latest',
        container_name: 'node-exporter',
        ports: ['9100:9100'],
        volumes: [
          '/proc:/host/proc:ro',
          '/sys:/host/sys:ro',
          '/:/rootfs:ro'
        ],
        command: [
          '--path.procfs=/host/proc',
          '--path.rootfs=/rootfs',
          '--path.sysfs=/host/sys',
          '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
        ],
        restart: 'unless-stopped'
      };
    }

    // cAdvisor
    if (options.features.includes('cadvisor')) {
      services.cadvisor = {
        image: 'gcr.io/cadvisor/cadvisor:latest',
        container_name: 'cadvisor',
        ports: ['8080:8080'],
        volumes: [
          '/:/rootfs:ro',
          '/var/run:/var/run:ro',
          '/sys:/sys:ro',
          '/var/lib/docker/:/var/lib/docker:ro',
          '/dev/disk/:/dev/disk:ro'
        ],
        privileged: true,
        restart: 'unless-stopped'
      };
    }

    // Blackbox Exporter
    if (options.features.includes('blackbox-exporter')) {
      services['blackbox-exporter'] = {
        image: 'prom/blackbox-exporter:latest',
        container_name: 'blackbox-exporter',
        ports: ['9115:9115'],
        volumes: ['./blackbox-exporter/blackbox-config.yml:/etc/blackbox_exporter/config.yml'],
        restart: 'unless-stopped'
      };
    }

    // Define volumes
    const volumes: Record<string, any> = {};
    
    if (options.features.includes('prometheus')) {
      volumes.prometheus_data = {};
    }
    
    if (options.features.includes('grafana')) {
      volumes.grafana_data = {};
    }
    
    if (options.features.includes('loki')) {
      volumes.loki_data = {};
    }
    
    if (options.features.includes('tempo')) {
      volumes.tempo_data = {};
    }

    const dockerCompose = {
      version: '3.8',
      services,
      volumes,
      networks: {
        monitoring: {
          driver: 'bridge'
        }
      }
    };

    // Add network to all services
    Object.keys(services).forEach(serviceName => {
      services[serviceName].networks = ['monitoring'];
    });

    writeFileSync(
      join(outputDir, 'docker-compose.yml'),
      this.yamlStringify(dockerCompose)
    );

    this.logger.info('Generated Docker Compose configuration');
  }

  private async generateKubernetesManifests(options: MonitoringGeneratorOptions, outputDir: string): Promise<void> {
    if (!options.kubernetes) return;

    const k8sDir = join(outputDir, 'kubernetes');
    this.ensureDirectoryExists(k8sDir);

    // Generate namespace
    const namespace = {
      apiVersion: 'v1',
      kind: 'Namespace',
      metadata: {
        name: options.kubernetes.namespace,
        labels: {
          name: options.kubernetes.namespace
        }
      }
    };

    writeFileSync(
      join(k8sDir, 'namespace.yaml'),
      this.yamlStringify(namespace)
    );

    // Generate Prometheus operator CRDs if needed
    if (options.features.includes('prometheus')) {
      await this.generatePrometheusOperatorManifests(options, k8sDir);
    }

    this.logger.info('Generated Kubernetes manifests');
  }

  private async generatePrometheusOperatorManifests(options: MonitoringGeneratorOptions, k8sDir: string): Promise<void> {
    // ServiceMonitor for application
    const serviceMonitor = {
      apiVersion: 'monitoring.coreos.com/v1',
      kind: 'ServiceMonitor',
      metadata: {
        name: options.projectName,
        namespace: options.kubernetes!.namespace,
        labels: {
          app: options.projectName
        }
      },
      spec: {
        selector: {
          matchLabels: {
            app: options.projectName
          }
        },
        endpoints: [
          {
            port: 'metrics',
            path: '/metrics',
            interval: '30s'
          }
        ]
      }
    };

    writeFileSync(
      join(k8sDir, 'service-monitor.yaml'),
      this.yamlStringify(serviceMonitor)
    );

    // PrometheusRule for alerting
    const prometheusRule = {
      apiVersion: 'monitoring.coreos.com/v1',
      kind: 'PrometheusRule',
      metadata: {
        name: `${options.projectName}-rules`,
        namespace: options.kubernetes!.namespace,
        labels: {
          app: options.projectName
        }
      },
      spec: {
        groups: [
          {
            name: `${options.projectName}.rules`,
            rules: options.prometheus.alertingRules.map(rule => ({
              alert: rule.name,
              expr: rule.expr,
              for: rule.for,
              labels: {
                severity: rule.severity,
                ...rule.labels
              },
              annotations: {
                summary: rule.summary,
                description: rule.description,
                ...rule.annotations
              }
            }))
          }
        ]
      }
    };

    writeFileSync(
      join(k8sDir, 'prometheus-rule.yaml'),
      this.yamlStringify(prometheusRule)
    );
  }

  private async generateDeploymentScripts(options: MonitoringGeneratorOptions, outputDir: string): Promise<void> {
    const scriptsDir = join(outputDir, 'scripts');
    this.ensureDirectoryExists(scriptsDir);

    // Start monitoring stack script
    const startScript = `#!/bin/bash
# Start monitoring stack for ${options.projectName}
# Generated by Xaheen CLI

set -e

echo "Starting monitoring stack..."

# Check if Docker is running
if ! docker info > /dev/null 2>&1; then
    echo " Docker is not running. Please start Docker first."
    exit 1
fi

# Create necessary directories
mkdir -p prometheus/rules
mkdir -p grafana/{dashboards,provisioning/{datasources,dashboards},data}
mkdir -p alertmanager
mkdir -p loki
mkdir -p tempo
mkdir -p opentelemetry

# Set permissions for Grafana
sudo chown -R 472:472 grafana/data || echo "Could not set Grafana permissions (this is ok on some systems)"

# Start services
echo " Starting Docker Compose services..."
docker-compose up -d

# Wait for services to be ready
echo " Waiting for services to be ready..."
sleep 30

# Check service health
echo " Checking service health..."

check_service() {
    local service_name=$1
    local url=$2
    local max_attempts=30
    local attempt=1
    
    while [ $attempt -le $max_attempts ]; do
        if curl -s "$url" > /dev/null 2>&1; then
            echo " $service_name is ready"
            return 0
        fi
        echo " Waiting for $service_name... (attempt $attempt/$max_attempts)"
        sleep 5
        ((attempt++))
    done
    
    echo " $service_name is not responding after $max_attempts attempts"
    return 1
}

${options.features.includes('prometheus') ? 'check_service "Prometheus" "http://localhost:9090/-/ready"' : ''}
${options.features.includes('grafana') ? 'check_service "Grafana" "http://localhost:3001/api/health"' : ''}
${options.features.includes('alertmanager') ? 'check_service "Alertmanager" "http://localhost:9093/-/ready"' : ''}
${options.features.includes('jaeger') ? 'check_service "Jaeger" "http://localhost:16686/"' : ''}

echo ""
echo " Monitoring stack is ready!"
echo ""
echo "Access URLs:"
${options.features.includes('prometheus') ? 'echo "   Prometheus: http://localhost:9090"' : ''}
${options.features.includes('grafana') ? 'echo "   Grafana: http://localhost:3001 (admin/admin)"' : ''}
${options.features.includes('alertmanager') ? 'echo "   Alertmanager: http://localhost:9093"' : ''}
${options.features.includes('jaeger') ? 'echo "   Jaeger: http://localhost:16686"' : ''}
echo ""
echo "To stop the stack, run: ./scripts/stop-monitoring.sh"
`;

    writeFileSync(join(scriptsDir, 'start-monitoring.sh'), startScript, { mode: 0o755 });

    // Stop monitoring stack script
    const stopScript = `#!/bin/bash
# Stop monitoring stack for ${options.projectName}
# Generated by Xaheen CLI

set -e

echo "Stopping monitoring stack..."

# Stop and remove containers
docker-compose down

echo " Monitoring stack stopped successfully"
echo ""
echo "To start the stack again, run: ./scripts/start-monitoring.sh"
echo "To remove all data, run: ./scripts/cleanup-monitoring.sh"
`;

    writeFileSync(join(scriptsDir, 'stop-monitoring.sh'), stopScript, { mode: 0o755 });

    // Cleanup script
    const cleanupScript = `#!/bin/bash
# Cleanup monitoring stack for ${options.projectName}
# Generated by Xaheen CLI

set -e

echo "  This will remove all monitoring data. Are you sure? (y/N)"
read -r response
if [[ ! "$response" =~ ^[Yy]$ ]]; then
    echo "Cleanup cancelled"
    exit 0
fi

echo "Cleaning up monitoring stack..."

# Stop containers
docker-compose down

# Remove volumes
docker-compose down -v

# Remove images (optional)
echo "Do you want to remove Docker images as well? (y/N)"
read -r response
if [[ "$response" =~ ^[Yy]$ ]]; then
    docker-compose down --rmi all
    echo " Monitoring stack and images removed"
else
    echo " Monitoring stack removed (images kept)"
fi

echo ""
echo "All monitoring data has been removed."
echo "To start fresh, run: ./scripts/start-monitoring.sh"
`;

    writeFileSync(join(scriptsDir, 'cleanup-monitoring.sh'), cleanupScript, { mode: 0o755 });

    this.logger.info('Generated deployment scripts');
  }

  private yamlStringify(obj: any): string {
    // Simple YAML stringifier - in production, use a proper YAML library
    return JSON.stringify(obj, null, 2)
      .replace(/"/g, '')
      .replace(/,$/gm, '')
      .replace(/\{$/gm, '')
      .replace(/\}$/gm, '')
      .replace(/\[$/gm, '')
      .replace(/\]$/gm, '')
      .replace(/^\s+/gm, (match) => '  '.repeat(match.length / 2));
  }
}